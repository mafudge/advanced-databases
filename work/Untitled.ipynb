{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e599cfb-3153-46fb-bd84-432293140e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "        .config(\"hive.metastore.uris\", \n",
    "                \"thrift://hive-metastore:9083\") \\\n",
    "        .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\") # Keeps the noise down!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5feb651b-1db3-44ad-9cb3-cab41a4dcd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(1, \"Fido\", \"Dog\",\"SPCA\",1),(2, \"Felix\", \"Cat\", \"SPCA\",2),(3, \"Rover\", \"Dog\",\"SPCA\",1)]\n",
    "cols = [\"id\",\"name\",\"type\",\"shelter\",\"years_at_shelter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22c29bd4-5cd8-4ee3-aeed-e9a4c87229c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+-------+----------------+\n",
      "| id| name|type|shelter|years_at_shelter|\n",
      "+---+-----+----+-------+----------------+\n",
      "|  1| Fido| Dog|   SPCA|               1|\n",
      "|  2|Felix| Cat|   SPCA|               2|\n",
      "|  3|Rover| Dog|   SPCA|               1|\n",
      "+---+-----+----+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(data = data, schema = cols).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2c3ae36-949e-4ecd-9f02-9497446bdb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+-------+----------------+\n",
      "| id| name|type|shelter|years_at_shelter|\n",
      "+---+-----+----+-------+----------------+\n",
      "|  1| Fido| Dog|   SPCA|               1|\n",
      "|  2|Felix| Cat|   SPCA|               2|\n",
      "|  3|Rover| Dog|   SPCA|               1|\n",
      "+---+-----+----+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pets = spark.createDataFrame(data = data, schema = cols)\n",
    "\n",
    "pets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ffe7e8-c023-4bd1-8b94-ea961ae3771d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Sort [name#32 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(name#32 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#80]\n",
      "   +- *(1) Project [name#32, type#33]\n",
      "      +- *(1) Filter (isnotnull(years_at_shelter#35L) AND (years_at_shelter#35L = 1))\n",
      "         +- *(1) Scan ExistingRDD[id#31L,name#32,type#33,shelter#34,years_at_shelter#35L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plan = pets.where(\"years_at_shelter=1\").sort(\"name\").select(\"name\",\"type\")\n",
    "plan.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7443775-cddb-4df3-bec4-f4669218ef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Sort [name#32 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(name#32 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#118]\n",
      "   +- *(1) Project [name#32, type#33]\n",
      "      +- *(1) Filter (isnotnull(years_at_shelter#35L) AND (years_at_shelter#35L = 1))\n",
      "         +- *(1) Scan ExistingRDD[id#31L,name#32,type#33,shelter#34,years_at_shelter#35L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "plan2 = pets.sort(\"name\").select(\"name\",\"type\").where(\"years_at_shelter=1\")\n",
    "plan2.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18eeffd7-d108-4947-a4bb-22778256b625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "create external table cdemo.grades (\n",
    "    year int,\n",
    "    semester string,\n",
    "    course string,\n",
    "    credit int,\n",
    "    grade string\n",
    ")\n",
    "row format delimited\n",
    "fields terminated by '\\t'\n",
    "location 'hdfs:///user/root/grades/*.tsv'\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "524747ec-0845-4b2a-9402-c82d020722bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+------+-----+\n",
      "|year|semester|course|credit|grade|\n",
      "+----+--------+------+------+-----+\n",
      "|2015|    Fall|IST101|     1|    A|\n",
      "|2015|    Fall|IST195|     3|    A|\n",
      "|2015|    Fall|IST233|     3|   B+|\n",
      "|2015|    Fall|SOC101|     3|   A-|\n",
      "|2015|    Fall|MAT221|     3|    C|\n",
      "|2016|    Fall|IST346|     3|    A|\n",
      "|2016|    Fall|CHE111|     4|   A-|\n",
      "|2016|    Fall|PSY120|     3|   B+|\n",
      "|2016|    Fall|IST256|     3|    A|\n",
      "|2016|    Fall|ENG121|     3|   B+|\n",
      "|2016|  Spring|GEO110|     3|   B+|\n",
      "|2016|  Spring|MAT222|     3|    A|\n",
      "|2016|  Spring|SOC121|     3|   C+|\n",
      "|2016|  Spring|BIO240|     3|   B-|\n",
      "|2017|  Spring|IST462|     3|    A|\n",
      "|2017|  Spring|MAT411|     3|    C|\n",
      "|2017|  Spring|SOC422|     3|   B-|\n",
      "|2017|  Spring|ENV201|     3|   A-|\n",
      "+----+--------+------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from cdemo.grades\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d46ad7af-c981-4f81-9b9a-502a427ae7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Sort [year#153 ASC NULLS FIRST, semester#154 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(year#153 ASC NULLS FIRST, semester#154 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#187]\n",
      "   +- *(2) HashAggregate(keys=[year#153, semester#154], functions=[sum(cast(credit#156 as bigint))])\n",
      "      +- Exchange hashpartitioning(year#153, semester#154, 200), ENSURE_REQUIREMENTS, [id=#183]\n",
      "         +- *(1) HashAggregate(keys=[year#153, semester#154], functions=[partial_sum(cast(credit#156 as bigint))])\n",
      "            +- Scan hive cdemo.grades [year#153, semester#154, credit#156], HiveTableRelation [`cdemo`.`grades`, org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe, Data Cols: [year#153, semester#154, course#155, credit#156, grade#157], Partition Cols: []]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "select sum(credit) as total_credits, year,semester\n",
    "from cdemo.grades\n",
    "group by year, semester\n",
    "order by year, semester\n",
    "\"\"\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc9ce9-ecef-44d7-a2b7-36e99cca4846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c957781-e18a-4cad-bb51-2533ac986726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b45ca85-bb7b-4576-9b2e-55adb4f2f0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638a9413-a23a-4954-bd33-e313d17afc53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a792ac-5ded-4307-b425-a5fe109f1483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd547e35-2756-4458-a95f-4d442c16db83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe7855b-51b0-4d85-ae00-67a4a999bb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "bucket = \"d-object-spark\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hive-metastore:9083\") \\\n",
    "        .config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:3.1.2,org.apache.spark:spark-avro_2.12:3.1.2\")\\\n",
    "        .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.access.key\", \"minio\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.secret.key\", \"SU2orange!\") \\\n",
    "        .config(\"spark.hadoop.fs.s3a.fast.upload\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.path.style.access\", True) \\\n",
    "        .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\") # Keeps the noise down!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ded082-7389-436e-833e-efb2cbe0f61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|2015\tFall\tIST101\t1\tA|\n",
      "|2015\tFall\tIST195\t3\tA|\n",
      "|2015\tFall\tIST233\t...|\n",
      "|2015\tFall\tSOC101\t...|\n",
      "|2015\tFall\tMAT221\t3\tC|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"file:///home/jovyan/datasets/grades/fall2015.tsv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c2e9f67-2140-4db7-bcf7-93246d177147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|2016\tFall\tIST346\t3\tA|\n",
      "|2016\tFall\tCHE111\t...|\n",
      "|2016\tFall\tPSY120\t...|\n",
      "|2016\tFall\tIST256\t3\tA|\n",
      "|2016\tFall\tENG121\t...|\n",
      "|2015\tFall\tIST101\t1\tA|\n",
      "|2015\tFall\tIST195\t3\tA|\n",
      "|2015\tFall\tIST233\t...|\n",
      "|2015\tFall\tSOC101\t...|\n",
      "|2015\tFall\tMAT221\t3\tC|\n",
      "|2016\tSpring\tGEO11...|\n",
      "|2016\tSpring\tMAT22...|\n",
      "|2016\tSpring\tSOC12...|\n",
      "|2016\tSpring\tBIO24...|\n",
      "|2017\tSpring\tIST46...|\n",
      "|2017\tSpring\tMAT41...|\n",
      "|2017\tSpring\tSOC42...|\n",
      "|2017\tSpring\tENV20...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"file:///home/jovyan/datasets/grades/\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd254a9-c38a-47d3-b01b-87448e2d9e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|2015\tFall\tIST101\t1\tA|\n",
      "|2015\tFall\tIST195\t3\tA|\n",
      "|2015\tFall\tIST233\t...|\n",
      "|2015\tFall\tSOC101\t...|\n",
      "|2015\tFall\tMAT221\t3\tC|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"s3a://unitd/grades/fall2015.tsv\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f3a77e2-6bc6-4220-a527-812d093c8cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|2016\tFall\tIST346\t3\tA|\n",
      "|2016\tFall\tCHE111\t...|\n",
      "|2016\tFall\tPSY120\t...|\n",
      "|2016\tFall\tIST256\t3\tA|\n",
      "|2016\tFall\tENG121\t...|\n",
      "|2015\tFall\tIST101\t1\tA|\n",
      "|2015\tFall\tIST195\t3\tA|\n",
      "|2015\tFall\tIST233\t...|\n",
      "|2015\tFall\tSOC101\t...|\n",
      "|2015\tFall\tMAT221\t3\tC|\n",
      "|2016\tSpring\tGEO11...|\n",
      "|2016\tSpring\tMAT22...|\n",
      "|2016\tSpring\tSOC12...|\n",
      "|2016\tSpring\tBIO24...|\n",
      "|2017\tSpring\tIST46...|\n",
      "|2017\tSpring\tMAT41...|\n",
      "|2017\tSpring\tSOC42...|\n",
      "|2017\tSpring\tENV20...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"s3a://unitd/grades/\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20e2236f-9781-47cb-bca8-8d50cfde1800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporary Location:  /tmp/spark-a2eaa4b7-cf7f-4c73-94c4-fc303b8d87ee/userFiles-bf6edabb-da6e-45fa-b9ed-df88e82dd375/fall2015.tsv\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkFiles\n",
    "\n",
    "spark.sparkContext.addFile(\"file:///home/jovyan/datasets/grades/fall2015.tsv\")\n",
    "\n",
    "print(\"Temporary Location: \", SparkFiles.get(\"fall2015.tsv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24bcaf7f-0376-4fb2-8951-94af7e8ea7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                 _c0|\n",
      "+--------------------+\n",
      "|2015\tFall\tIST101\t1\tA|\n",
      "|2015\tFall\tIST195\t3\tA|\n",
      "|2015\tFall\tIST233\t...|\n",
      "|2015\tFall\tSOC101\t...|\n",
      "|2015\tFall\tMAT221\t3\tC|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(SparkFiles.get(\"fall2015.tsv\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf7daa2d-c241-423c-bbd0-5d5e15ffe0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- price: double (nullable = true)\n",
      " |-- symbol: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\",True).option(\"inferSchema\",True) \\\n",
    "    .csv(\"file:///home/jovyan/datasets/stocks/stocks.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2258b7ba-431c-4fcd-8d28-7ee1285f1dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"sep\",\"\\t\").option(\"inferSchema\",True).csv(\"file:///home/jovyan/datasets/grades/\")\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "767957f7-f0a1-49e0-8cff-a0fe0e5b4531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|  price|symbol|\n",
      "+-------+------+\n",
      "| 126.82|  AAPL|\n",
      "|3098.12|  AMZN|\n",
      "| 251.11|    FB|\n",
      "|1725.05|  GOOG|\n",
      "| 128.39|   IBM|\n",
      "| 212.55|  MSFT|\n",
      "|   78.0|   NET|\n",
      "|  497.0|  NFLX|\n",
      "|  823.8|  TSLA|\n",
      "|  45.11|  TWTR|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"file:///home/jovyan/datasets/stocks/stocks.parquet\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56fb85d2-40a6-4a42-b28e-f8cb0528a9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"multiline\",True).json(\"/home/jovyan/datasets/json-samples/stocks.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bd6e390-1993-4fa3-97a7-bc1e1bc9157c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- price: double (nullable = true)\n",
      " |-- symbol: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0040cb51-ed70-4398-acd8-9fa912b95403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      " |-- _c4: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades = spark.read.option(\"sep\",\"\\t\").option(\"inferSchema\",True).csv(\"file:///home/jovyan/datasets/grades/\")\n",
    "grades.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48e9156c-c895-496f-9f96-9d0653f0d6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+---+---+\n",
      "| _c0| _c1|   _c2|_c3|_c4|\n",
      "+----+----+------+---+---+\n",
      "|2016|Fall|IST346|  3|  A|\n",
      "|2016|Fall|CHE111|  4| A-|\n",
      "|2016|Fall|PSY120|  3| B+|\n",
      "|2016|Fall|IST256|  3|  A|\n",
      "|2016|Fall|ENG121|  3| B+|\n",
      "+----+----+------+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cdc9ca3-055f-4636-bb8c-5bbc8f5885b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+------+---+---+\n",
      "|year|   _c1|   _c2|_c3|_c4|\n",
      "+----+------+------+---+---+\n",
      "|2016|  Fall|IST346|  3|  A|\n",
      "|2016|  Fall|CHE111|  4| A-|\n",
      "|2016|  Fall|PSY120|  3| B+|\n",
      "|2016|  Fall|IST256|  3|  A|\n",
      "|2016|  Fall|ENG121|  3| B+|\n",
      "|2015|  Fall|IST101|  1|  A|\n",
      "|2015|  Fall|IST195|  3|  A|\n",
      "|2015|  Fall|IST233|  3| B+|\n",
      "|2015|  Fall|SOC101|  3| A-|\n",
      "|2015|  Fall|MAT221|  3|  C|\n",
      "|2016|Spring|GEO110|  3| B+|\n",
      "|2016|Spring|MAT222|  3|  A|\n",
      "|2016|Spring|SOC121|  3| C+|\n",
      "|2016|Spring|BIO240|  3| B-|\n",
      "|2017|Spring|IST462|  3|  A|\n",
      "|2017|Spring|MAT411|  3|  C|\n",
      "|2017|Spring|SOC422|  3| B-|\n",
      "|2017|Spring|ENV201|  3| A-|\n",
      "+----+------+------+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades2 = grades.withColumnRenamed(\"_c0\",\"year\")\n",
    "grades2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "385ffa82-6a20-4b86-b4b9-bd4412ecffb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+-----+\n",
      "|year|semester|course|credits|grade|\n",
      "+----+--------+------+-------+-----+\n",
      "|2016|    Fall|IST346|      3|    A|\n",
      "|2016|    Fall|CHE111|      4|   A-|\n",
      "|2016|    Fall|PSY120|      3|   B+|\n",
      "|2016|    Fall|IST256|      3|    A|\n",
      "|2016|    Fall|ENG121|      3|   B+|\n",
      "+----+--------+------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades3 = grades.toDF(\"year\", \"semester\", \"course\",\"credits\", \"grade\")\n",
    "grades3.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a301d43-9e73-4a15-a92a-7940bb75e2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- credits: integer (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades = spark.read.option(\"sep\",\"\\t\").option(\"inferSchema\",True) \\\n",
    "    .csv(\"file:///home/jovyan/datasets/grades/\") \\\n",
    "    .toDF(\"year\", \"semester\", \"course\",\"credits\", \"grade\")\n",
    "grades.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "534e5552-0ba0-4942-b440-4936513338ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+-----+\n",
      "|year|semester|course|credits|grade|\n",
      "+----+--------+------+-------+-----+\n",
      "|2016|    Fall|IST346|      3|    A|\n",
      "|2016|    Fall|CHE111|      4|   A-|\n",
      "|2016|    Fall|PSY120|      3|   B+|\n",
      "|2016|    Fall|IST256|      3|    A|\n",
      "|2016|    Fall|ENG121|      3|   B+|\n",
      "+----+--------+------+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "576c1eea-d83f-49dd-8557-1d2c8d85de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+-----+---------+\n",
      "|year|semester|course|credits|grade|next_year|\n",
      "+----+--------+------+-------+-----+---------+\n",
      "|2016|    Fall|IST346|      3|    A|     2017|\n",
      "|2016|    Fall|CHE111|      4|   A-|     2017|\n",
      "|2016|    Fall|PSY120|      3|   B+|     2017|\n",
      "|2016|    Fall|IST256|      3|    A|     2017|\n",
      "|2016|    Fall|ENG121|      3|   B+|     2017|\n",
      "|2015|    Fall|IST101|      1|    A|     2016|\n",
      "|2015|    Fall|IST195|      3|    A|     2016|\n",
      "+----+--------+------+-------+-----+---------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col \n",
    "grades4 = grades.withColumn(\"next_year\", col(\"year\") + 1)\n",
    "grades4.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6dca90fc-a82d-41f5-afcb-c10a9abd6dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|credits|grade|\n",
      "+-------+-----+\n",
      "|      3|    A|\n",
      "|      4|   A-|\n",
      "|      3|   B+|\n",
      "|      3|    A|\n",
      "|      3|   B+|\n",
      "|      1|    A|\n",
      "|      3|    A|\n",
      "|      3|   B+|\n",
      "|      3|   A-|\n",
      "|      3|    C|\n",
      "|      3|   B+|\n",
      "|      3|    A|\n",
      "|      3|   C+|\n",
      "|      3|   B-|\n",
      "|      3|    A|\n",
      "|      3|    C|\n",
      "|      3|   B-|\n",
      "|      3|   A-|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "credletter = grades.select(\"credits\",\"grade\")\n",
    "credletter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df6036a8-e9f7-4f56-9495-2e7cd37e04c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- semester: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- credits: integer (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e9a3a8c7-3904-4b06-8f6b-927273519328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|year|semester|\n",
      "+----+--------+\n",
      "|2016|    Fall|\n",
      "|2017|  Spring|\n",
      "|2015|    Fall|\n",
      "|2016|  Spring|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades.select(\"year\",\"semester\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0dc7a7d9-6fb2-4f84-9c43-d03cf24f59b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+-----+\n",
      "|year|semester|course|credits|grade|\n",
      "+----+--------+------+-------+-----+\n",
      "|2016|    Fall|IST346|      3|    A|\n",
      "|2016|    Fall|CHE111|      4|   A-|\n",
      "|2016|    Fall|PSY120|      3|   B+|\n",
      "|2016|    Fall|IST256|      3|    A|\n",
      "|2016|    Fall|ENG121|      3|   B+|\n",
      "|2016|  Spring|GEO110|      3|   B+|\n",
      "|2016|  Spring|MAT222|      3|    A|\n",
      "|2016|  Spring|SOC121|      3|   C+|\n",
      "|2016|  Spring|BIO240|      3|   B-|\n",
      "+----+--------+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades.where(\"year = 2016\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cf9f0a99-735d-4b52-a88e-169e6b98f569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+-----+\n",
      "|year|semester|course|credits|grade|\n",
      "+----+--------+------+-------+-----+\n",
      "|2016|    Fall|IST346|      3|    A|\n",
      "|2016|    Fall|IST256|      3|    A|\n",
      "|2015|    Fall|IST101|      1|    A|\n",
      "|2015|    Fall|IST195|      3|    A|\n",
      "|2016|  Spring|MAT222|      3|    A|\n",
      "|2017|  Spring|IST462|      3|    A|\n",
      "+----+--------+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades.filter(\"grade = 'A'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "25f0eca2-296a-4da3-90e0-a38b7d82bb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+-----+\n",
      "|year|semester|course|credits|grade|\n",
      "+----+--------+------+-------+-----+\n",
      "|2016|    Fall|IST346|      3|    A|\n",
      "|2016|    Fall|IST256|      3|    A|\n",
      "|2015|    Fall|IST101|      1|    A|\n",
      "|2015|    Fall|IST195|      3|    A|\n",
      "|2016|  Spring|MAT222|      3|    A|\n",
      "|2017|  Spring|IST462|      3|    A|\n",
      "+----+--------+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades.where( grades.grade == 'A' ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4a74dd36-a78b-4264-9128-b462c22f2d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+-----+\n",
      "|year|semester|course|credits|grade|\n",
      "+----+--------+------+-------+-----+\n",
      "|2016|    Fall|IST346|      3|    A|\n",
      "|2016|    Fall|IST256|      3|    A|\n",
      "|2015|    Fall|IST101|      1|    A|\n",
      "|2015|    Fall|IST195|      3|    A|\n",
      "|2016|  Spring|MAT222|      3|    A|\n",
      "|2017|  Spring|IST462|      3|    A|\n",
      "+----+--------+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades.where( grades[\"grade\"] == 'A' ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6a7105c3-a628-4c57-8671-4cd0996f3df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+-----+\n",
      "|year|semester|course|credits|grade|\n",
      "+----+--------+------+-------+-----+\n",
      "|2016|    Fall|IST346|      3|    A|\n",
      "|2016|    Fall|CHE111|      4|   A-|\n",
      "|2016|    Fall|IST256|      3|    A|\n",
      "|2015|    Fall|IST101|      1|    A|\n",
      "|2015|    Fall|IST195|      3|    A|\n",
      "|2015|    Fall|SOC101|      3|   A-|\n",
      "|2016|  Spring|MAT222|      3|    A|\n",
      "|2017|  Spring|IST462|      3|    A|\n",
      "|2017|  Spring|ENV201|      3|   A-|\n",
      "+----+--------+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades.where(\"grade = 'A' or grade = 'A-'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2edabfbd-ddb1-4944-b018-e9a5b08a0abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+-----+\n",
      "|year|semester|course|credits|grade|\n",
      "+----+--------+------+-------+-----+\n",
      "|2016|    Fall|IST346|      3|    A|\n",
      "|2016|    Fall|IST256|      3|    A|\n",
      "|2015|    Fall|IST101|      1|    A|\n",
      "|2015|    Fall|IST195|      3|    A|\n",
      "|2016|  Spring|MAT222|      3|    A|\n",
      "|2017|  Spring|IST462|      3|    A|\n",
      "+----+--------+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades.where( (grades.grade == 'A') | (grades.grade == \"-A\") ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a82efe5-c4d5-4ae9-a146-65107ba0d7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+-----+\n",
      "|year|semester|course|credits|grade|\n",
      "+----+--------+------+-------+-----+\n",
      "|2016|  Spring|MAT222|      3|    A|\n",
      "|2017|  Spring|IST462|      3|    A|\n",
      "|2016|    Fall|IST346|      3|    A|\n",
      "|2015|    Fall|IST101|      1|    A|\n",
      "|2015|    Fall|IST195|      3|    A|\n",
      "|2016|    Fall|IST256|      3|    A|\n",
      "|2016|    Fall|CHE111|      4|   A-|\n",
      "|2015|    Fall|SOC101|      3|   A-|\n",
      "|2017|  Spring|ENV201|      3|   A-|\n",
      "|2016|  Spring|GEO110|      3|   B+|\n",
      "|2016|    Fall|PSY120|      3|   B+|\n",
      "|2016|    Fall|ENG121|      3|   B+|\n",
      "|2015|    Fall|IST233|      3|   B+|\n",
      "|2017|  Spring|SOC422|      3|   B-|\n",
      "|2016|  Spring|BIO240|      3|   B-|\n",
      "|2015|    Fall|MAT221|      3|    C|\n",
      "|2017|  Spring|MAT411|      3|    C|\n",
      "|2016|  Spring|SOC121|      3|   C+|\n",
      "+----+--------+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades.sort(\"grade\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8d4a8cc8-2643-49fc-b68b-936d6754fd03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+-----+\n",
      "|year|semester|course|credits|grade|\n",
      "+----+--------+------+-------+-----+\n",
      "|2016|  Spring|SOC121|      3|   C+|\n",
      "|2015|    Fall|MAT221|      3|    C|\n",
      "|2017|  Spring|MAT411|      3|    C|\n",
      "|2016|  Spring|BIO240|      3|   B-|\n",
      "|2017|  Spring|SOC422|      3|   B-|\n",
      "|2016|    Fall|PSY120|      3|   B+|\n",
      "|2015|    Fall|IST233|      3|   B+|\n",
      "|2016|    Fall|ENG121|      3|   B+|\n",
      "|2016|  Spring|GEO110|      3|   B+|\n",
      "|2017|  Spring|ENV201|      3|   A-|\n",
      "|2015|    Fall|SOC101|      3|   A-|\n",
      "|2016|    Fall|CHE111|      4|   A-|\n",
      "|2016|    Fall|IST346|      3|    A|\n",
      "|2015|    Fall|IST195|      3|    A|\n",
      "|2016|    Fall|IST256|      3|    A|\n",
      "|2016|  Spring|MAT222|      3|    A|\n",
      "|2015|    Fall|IST101|      1|    A|\n",
      "|2017|  Spring|IST462|      3|    A|\n",
      "+----+--------+------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades.sort(grades.grade.desc() ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d3b91da8-e654-478d-a774-e6d5d439098c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semesters in which our grade was a \"C\"\n",
    "x = grades.filter( (grades.grade == \"C\") | (grades.grade == \"C+\") | (grades.grade == \"C-\")) \\\n",
    "    .select(\"year\",\"semester\",\"course\",\"grade\") \\\n",
    "    .sort(\"course\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "14647dff-a1fe-4845-aafc-152b4fff4902",
   "metadata": {},
   "outputs": [],
   "source": [
    " y = x.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6586d244-7a4f-4705-8731-6201f7bc096b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>semester</th>\n",
       "      <th>course</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>Fall</td>\n",
       "      <td>MAT221</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>Spring</td>\n",
       "      <td>MAT411</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>Spring</td>\n",
       "      <td>SOC121</td>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year semester  course grade\n",
       "0  2015     Fall  MAT221     C\n",
       "1  2017   Spring  MAT411     C\n",
       "2  2016   Spring  SOC121    C+"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "59b07bc6-5264-4fc9-affd-756e30662534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|year|class_taken|\n",
      "+----+-----------+\n",
      "|2015|          5|\n",
      "|2016|          9|\n",
      "|2017|          4|\n",
      "+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum,min,max,count,avg\n",
    "grades.groupBy(\"year\").agg( \n",
    "        count(\"year\").alias(\"class_taken\") \n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "717d6833-59c6-40be-8003-5919cbf7b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = grades.groupBy(\"year\",grades.semester).agg(\n",
    "    count(\"*\").alias(\"classes_taken\"),\n",
    "    sum(grades.credits).alias(\"total_credits\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "51056ecf-00ce-497f-ac5f-3771fb5b8093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-------------+-------------+\n",
      "|year|semester|classes_taken|total_credits|\n",
      "+----+--------+-------------+-------------+\n",
      "|2016|    Fall|            5|           16|\n",
      "|2017|  Spring|            4|           12|\n",
      "|2015|    Fall|            5|           13|\n",
      "|2016|  Spring|            4|           12|\n",
      "+----+--------+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d691d603-9e34-4a3a-a7e0-151cff219e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|letter_grade|points|\n",
      "+------------+------+\n",
      "|           A|   4.0|\n",
      "|          A-| 3.666|\n",
      "|          B+| 3.333|\n",
      "|           B|   3.0|\n",
      "|          B-| 2.666|\n",
      "|          C+| 2.333|\n",
      "|           C|   2.0|\n",
      "|          C-| 1.666|\n",
      "|           D|   1.0|\n",
      "|           F|   0.0|\n",
      "+------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gradepoints = spark.read.option(\"inferSchema\",True) \\\n",
    "    .csv(\"file:///home/jovyan/datasets/courses/grade-points.csv\") \\\n",
    "    .toDF(\"letter_grade\",\"points\")\n",
    "gradepoints.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4ff79702-505f-460b-8079-1c406cabcb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|course_code|      course_title|\n",
      "+-----------+------------------+\n",
      "|     BIO240|        Biology II|\n",
      "|     CHE111|        Chemstry I|\n",
      "|     ENG121|    English Lit. I|\n",
      "|     ENV201|       Env Science|\n",
      "|     GEO110|         Geology I|\n",
      "|     IST101|    Freshmen Forum|\n",
      "|     IST195| Info Technologies|\n",
      "|     IST233| Cloud Computing I|\n",
      "|     IST256|     Programming I|\n",
      "|     IST346|Cloud Computing II|\n",
      "|     IST462|    Programming II|\n",
      "|     IST344|    Info Reporting|\n",
      "|     MAT221|      Statistics I|\n",
      "|     MAT222|     Statistics II|\n",
      "|     PSY120|      Psychology I|\n",
      "|     SOC101|       Sociology I|\n",
      "|     SOC121|      Sociology II|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "courses = spark.read.option(\"inferSchema\",True) \\\n",
    "    .csv(\"file:///home/jovyan/datasets/courses/courses.csv\") \\\n",
    "    .toDF(\"course_code\",\"course_title\")\n",
    "courses.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9e3ddcef-b5a2-4050-bbbc-2e17c6a816bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = grades.join(courses, courses.course_code == grades.course, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "13206f04-4528-4a9a-96b7-1831c79792b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+-----+-----------+------------------+\n",
      "|year|semester|course|credits|grade|course_code|      course_title|\n",
      "+----+--------+------+-------+-----+-----------+------------------+\n",
      "|2016|    Fall|IST346|      3|    A|     IST346|Cloud Computing II|\n",
      "|2016|    Fall|CHE111|      4|   A-|     CHE111|        Chemstry I|\n",
      "|2016|    Fall|PSY120|      3|   B+|     PSY120|      Psychology I|\n",
      "|2016|    Fall|IST256|      3|    A|     IST256|     Programming I|\n",
      "|2016|    Fall|ENG121|      3|   B+|     ENG121|    English Lit. I|\n",
      "|2015|    Fall|IST101|      1|    A|     IST101|    Freshmen Forum|\n",
      "|2015|    Fall|IST195|      3|    A|     IST195| Info Technologies|\n",
      "|2015|    Fall|IST233|      3|   B+|     IST233| Cloud Computing I|\n",
      "|2015|    Fall|SOC101|      3|   A-|     SOC101|       Sociology I|\n",
      "|2015|    Fall|MAT221|      3|    C|     MAT221|      Statistics I|\n",
      "|2016|  Spring|GEO110|      3|   B+|     GEO110|         Geology I|\n",
      "|2016|  Spring|MAT222|      3|    A|     MAT222|     Statistics II|\n",
      "|2016|  Spring|SOC121|      3|   C+|     SOC121|      Sociology II|\n",
      "|2016|  Spring|BIO240|      3|   B-|     BIO240|        Biology II|\n",
      "|2017|  Spring|IST462|      3|    A|     IST462|    Programming II|\n",
      "|2017|  Spring|ENV201|      3|   A-|     ENV201|       Env Science|\n",
      "+----+--------+------+-------+-----+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3b356b58-810a-4d4b-beea-b90c9e58cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = grades.join(courses, courses.course_code == grades.course, \"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a207c4ae-1e85-4a96-b85e-1e3507b93bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+-------+-----+-----------+------------------+\n",
      "|year|semester|course|credits|grade|course_code|      course_title|\n",
      "+----+--------+------+-------+-----+-----------+------------------+\n",
      "|2015|    Fall|SOC101|      3|   A-|     SOC101|       Sociology I|\n",
      "|2016|  Spring|BIO240|      3|   B-|     BIO240|        Biology II|\n",
      "|2017|  Spring|IST462|      3|    A|     IST462|    Programming II|\n",
      "|2015|    Fall|IST101|      1|    A|     IST101|    Freshmen Forum|\n",
      "|2016|  Spring|MAT222|      3|    A|     MAT222|     Statistics II|\n",
      "|2017|  Spring|ENV201|      3|   A-|     ENV201|       Env Science|\n",
      "|2015|    Fall|MAT221|      3|    C|     MAT221|      Statistics I|\n",
      "|null|    null|  null|   null| null|     IST344|    Info Reporting|\n",
      "|2016|  Spring|SOC121|      3|   C+|     SOC121|      Sociology II|\n",
      "|2016|    Fall|CHE111|      4|   A-|     CHE111|        Chemstry I|\n",
      "|2016|    Fall|IST346|      3|    A|     IST346|Cloud Computing II|\n",
      "|2016|    Fall|PSY120|      3|   B+|     PSY120|      Psychology I|\n",
      "|2015|    Fall|IST233|      3|   B+|     IST233| Cloud Computing I|\n",
      "|2015|    Fall|IST195|      3|    A|     IST195| Info Technologies|\n",
      "|2016|  Spring|GEO110|      3|   B+|     GEO110|         Geology I|\n",
      "|2016|    Fall|ENG121|      3|   B+|     ENG121|    English Lit. I|\n",
      "|2017|  Spring|MAT411|      3|    C|       null|              null|\n",
      "|2017|  Spring|SOC422|      3|   B-|       null|              null|\n",
      "|2016|    Fall|IST256|      3|    A|     IST256|     Programming I|\n",
      "+----+--------+------+-------+-----+-----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c98312e5-86e8-46c3-a4f7-e5afbbe2102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fallgrades = grades.select(\"year\",\"semester\",\"course\").where(\"semester = 'Fall'\")\n",
    "springgrades = grades.select(\"year\",\"semester\",\"course\").where(\"semester = 'Spring'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4568cc3c-1d8c-468e-84e3-3c767e5cd8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+------+\n",
      "|year|semester|course|\n",
      "+----+--------+------+\n",
      "|2016|    Fall|IST346|\n",
      "|2016|    Fall|CHE111|\n",
      "|2016|    Fall|PSY120|\n",
      "|2016|    Fall|IST256|\n",
      "|2016|    Fall|ENG121|\n",
      "|2015|    Fall|IST101|\n",
      "|2015|    Fall|IST195|\n",
      "|2015|    Fall|IST233|\n",
      "|2015|    Fall|SOC101|\n",
      "|2015|    Fall|MAT221|\n",
      "|2016|  Spring|GEO110|\n",
      "|2016|  Spring|MAT222|\n",
      "|2016|  Spring|SOC121|\n",
      "|2016|  Spring|BIO240|\n",
      "|2017|  Spring|IST462|\n",
      "|2017|  Spring|MAT411|\n",
      "|2017|  Spring|SOC422|\n",
      "|2017|  Spring|ENV201|\n",
      "+----+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cgrades = fallgrades.union(springgrades)\n",
    "cgrades.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3703a33d-aca1-462c-a002-74374117426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "01fb359a-5982-4d6f-8d8c-d8dab339aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=BooleanType())\n",
    "def inMajor(course):\n",
    "    return course.startswith(\"IST\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e25e1792-b257-466d-8b94-166ff87568c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = grades.select(\"course\", inMajor(grades.course).alias(\"course_in_major\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b81fe299-95ed-4672-9d26-8b3e57d57498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- course: string (nullable = true)\n",
      " |-- course_in_major: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1bf9e26f-2cf8-4c05-a99f-a9902abcca11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|course|course_in_major|\n",
      "+------+---------------+\n",
      "|IST346|           true|\n",
      "|CHE111|          false|\n",
      "|PSY120|          false|\n",
      "|IST256|           true|\n",
      "|ENG121|          false|\n",
      "|IST101|           true|\n",
      "|IST195|           true|\n",
      "|IST233|           true|\n",
      "|SOC101|          false|\n",
      "|MAT221|          false|\n",
      "|GEO110|          false|\n",
      "|MAT222|          false|\n",
      "|SOC121|          false|\n",
      "|BIO240|          false|\n",
      "|IST462|           true|\n",
      "|MAT411|          false|\n",
      "|SOC422|          false|\n",
      "|ENV201|          false|\n",
      "+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1abd5b30-dedd-44fa-85e6-999466a410fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|course|course_in_major|\n",
      "+------+---------------+\n",
      "|IST346|           true|\n",
      "|IST256|           true|\n",
      "|IST101|           true|\n",
      "|IST195|           true|\n",
      "|IST233|           true|\n",
      "|IST462|           true|\n",
      "+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grades.select(\"course\", inMajor(grades.course).alias(\"course_in_major\") ) \\\n",
    "    .where(col(\"course_in_major\") == True) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0905dcc6-a3ed-4f98-b39d-8aaa5582f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "places = spark.read.json(\"file:///home/jovyan/datasets/json-samples/google-places.json\", multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3a13e16a-d229-4664-9848-b7f805801974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_status: string (nullable = true)\n",
      " |-- geometry: struct (nullable = true)\n",
      " |    |-- location: struct (nullable = true)\n",
      " |    |    |-- lat: double (nullable = true)\n",
      " |    |    |-- lng: double (nullable = true)\n",
      " |    |-- viewport: struct (nullable = true)\n",
      " |    |    |-- northeast: struct (nullable = true)\n",
      " |    |    |    |-- lat: double (nullable = true)\n",
      " |    |    |    |-- lng: double (nullable = true)\n",
      " |    |    |-- southwest: struct (nullable = true)\n",
      " |    |    |    |-- lat: double (nullable = true)\n",
      " |    |    |    |-- lng: double (nullable = true)\n",
      " |-- icon: string (nullable = true)\n",
      " |-- icon_background_color: string (nullable = true)\n",
      " |-- icon_mask_base_uri: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- opening_hours: struct (nullable = true)\n",
      " |    |-- open_now: boolean (nullable = true)\n",
      " |-- photos: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- height: long (nullable = true)\n",
      " |    |    |-- html_attributions: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |-- photo_reference: string (nullable = true)\n",
      " |    |    |-- width: long (nullable = true)\n",
      " |-- place_id: string (nullable = true)\n",
      " |-- plus_code: struct (nullable = true)\n",
      " |    |-- compound_code: string (nullable = true)\n",
      " |    |-- global_code: string (nullable = true)\n",
      " |-- price_level: long (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- reference: string (nullable = true)\n",
      " |-- scope: string (nullable = true)\n",
      " |-- types: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- user_ratings_total: long (nullable = true)\n",
      " |-- vicinity: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "places.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4300a213-d32f-498d-a5fd-22bcea61b530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+------------------+\n",
      "|                name|              lat|               lng|\n",
      "+--------------------+-----------------+------------------+\n",
      "|            Syracuse|       43.0481221|-76.14742439999999|\n",
      "|Crowne Plaza Syra...|       43.0476078|       -76.1417642|\n",
      "|  The Parkview Hotel|       43.0476157|        -76.140986|\n",
      "|Jefferson Clinton...|       43.0472894|-76.15385049999999|\n",
      "|Courtyard by Marr...|       43.0488846|       -76.1561175|\n",
      "|Quality Inn & Sui...|43.05264399999999|-76.14681999999999|\n",
      "| Syracuse University|       43.0391534|       -76.1351158|\n",
      "|Collegian Hotel &...|       43.0464172|-76.13539879999999|\n",
      "|  Dinosaur Bar-B-Que|       43.0526411|-76.15469379999999|\n",
      "|Hotel Skyler Syra...|43.04396249999999|-76.13607999999999|\n",
      "|Sheraton Syracuse...|43.04123120000001|       -76.1338203|\n",
      "|Syracuse Crunch H...|       43.0446639|       -76.1481366|\n",
      "| Mulroy Civic Center|       43.0457297|       -76.1483396|\n",
      "|     Crouse Hospital|       43.0414634|        -76.138599|\n",
      "|       Pastabilities|        43.048302|        -76.155406|\n",
      "|US Social Securit...|        43.050228|        -76.154804|\n",
      "|Syracuse VA Medic...|43.03901020000001|       -76.1389683|\n",
      "|Dr. James W. Hols...|        43.042709|        -76.140511|\n",
      "|Cleary Lynn Marie MD|43.04229789999999|       -76.1395979|\n",
      "|            Eastside|43.03426049999999|       -76.1242405|\n",
      "+--------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "places.select(\"name\", \"geometry.location.lat\", places.geometry.location.lng.alias(\"lng\") ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7d045c2b-060c-4f9a-9e47-614576b592c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+---------------------+-----------------+\n",
      "|                name|geometry.location.lat|geometry.location.lat|             type|\n",
      "+--------------------+---------------------+---------------------+-----------------+\n",
      "|            Syracuse|           43.0481221|           43.0481221|         locality|\n",
      "|            Syracuse|           43.0481221|           43.0481221|        political|\n",
      "|Crowne Plaza Syra...|           43.0476078|           43.0476078|          lodging|\n",
      "|Crowne Plaza Syra...|           43.0476078|           43.0476078|point_of_interest|\n",
      "|Crowne Plaza Syra...|           43.0476078|           43.0476078|    establishment|\n",
      "|  The Parkview Hotel|           43.0476157|           43.0476157|          lodging|\n",
      "|  The Parkview Hotel|           43.0476157|           43.0476157|point_of_interest|\n",
      "|  The Parkview Hotel|           43.0476157|           43.0476157|    establishment|\n",
      "|Jefferson Clinton...|           43.0472894|           43.0472894|          lodging|\n",
      "|Jefferson Clinton...|           43.0472894|           43.0472894|point_of_interest|\n",
      "|Jefferson Clinton...|           43.0472894|           43.0472894|    establishment|\n",
      "|Courtyard by Marr...|           43.0488846|           43.0488846|          lodging|\n",
      "|Courtyard by Marr...|           43.0488846|           43.0488846|point_of_interest|\n",
      "|Courtyard by Marr...|           43.0488846|           43.0488846|    establishment|\n",
      "|Quality Inn & Sui...|    43.05264399999999|    43.05264399999999|          lodging|\n",
      "|Quality Inn & Sui...|    43.05264399999999|    43.05264399999999|point_of_interest|\n",
      "|Quality Inn & Sui...|    43.05264399999999|    43.05264399999999|    establishment|\n",
      "| Syracuse University|           43.0391534|           43.0391534|       university|\n",
      "| Syracuse University|           43.0391534|           43.0391534|point_of_interest|\n",
      "| Syracuse University|           43.0391534|           43.0391534|    establishment|\n",
      "+--------------------+---------------------+---------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "places.select(\"name\", \"geometry.location.lat\", \"geometry.location.lat\", explode(\"types\").alias(\"type\") ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2d5ed3a7-c2a4-466b-8860-24dbe2ec00d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------+---------------------+-------------+\n",
      "|                name|geometry.location.lat|geometry.location.lat|         type|\n",
      "+--------------------+---------------------+---------------------+-------------+\n",
      "|Crowne Plaza Syra...|           43.0476078|           43.0476078|establishment|\n",
      "|  The Parkview Hotel|           43.0476157|           43.0476157|establishment|\n",
      "|Jefferson Clinton...|           43.0472894|           43.0472894|establishment|\n",
      "|Courtyard by Marr...|           43.0488846|           43.0488846|establishment|\n",
      "|Quality Inn & Sui...|    43.05264399999999|    43.05264399999999|establishment|\n",
      "| Syracuse University|           43.0391534|           43.0391534|establishment|\n",
      "|Collegian Hotel &...|           43.0464172|           43.0464172|establishment|\n",
      "|  Dinosaur Bar-B-Que|           43.0526411|           43.0526411|establishment|\n",
      "|Hotel Skyler Syra...|    43.04396249999999|    43.04396249999999|establishment|\n",
      "|Sheraton Syracuse...|    43.04123120000001|    43.04123120000001|establishment|\n",
      "|Syracuse Crunch H...|           43.0446639|           43.0446639|establishment|\n",
      "| Mulroy Civic Center|           43.0457297|           43.0457297|establishment|\n",
      "|     Crouse Hospital|           43.0414634|           43.0414634|establishment|\n",
      "|       Pastabilities|            43.048302|            43.048302|establishment|\n",
      "|US Social Securit...|            43.050228|            43.050228|establishment|\n",
      "|Syracuse VA Medic...|    43.03901020000001|    43.03901020000001|establishment|\n",
      "|Dr. James W. Hols...|            43.042709|            43.042709|establishment|\n",
      "|Cleary Lynn Marie MD|    43.04229789999999|    43.04229789999999|establishment|\n",
      "+--------------------+---------------------+---------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "places.select(\"name\", \"geometry.location.lat\", \"geometry.location.lat\", explode(\"types\").alias(\"type\") ) \\\n",
    "    .where(col(\"type\") == 'establishment') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b2866121-8fad-4efc-973b-09e995d367fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Semester</th>\n",
       "      <th>CourseCount</th>\n",
       "      <th>TotalCredits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>Spring</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>Fall</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Semester  CourseCount  TotalCredits\n",
       "0  2016   Spring            4            12\n",
       "1  2016     Fall            5            16"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades = spark.read.option(\"header\",False).option(\"inferSchema\", True).option(\"sep\", \"\\t\")\\\n",
    "    .csv(\"file:///home/jovyan/datasets/grades/*.tsv\")\\\n",
    "    .toDF(\"Year\", \"Semester\", \"Course\", \"Credits\", \"Grade\")\n",
    "\n",
    "termcredits = grades.groupBy(\"Year\", \"Semester\").agg( \\\n",
    "    count(\"*\").alias(\"CourseCount\"), \n",
    "    sum(\"Credits\").alias(\"TotalCredits\") \\\n",
    "    ).sort(\"Year\",col(\"Semester\").desc())\n",
    "\n",
    "final = termcredits.filter(\"Year=2016\")\n",
    "\n",
    "final.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "681c7a96-6ec3-4bf1-9b0a-a6e0d66a53f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Sort [Year#2098 ASC NULLS FIRST, Semester#2099 DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(Year#2098 ASC NULLS FIRST, Semester#2099 DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [id=#1493]\n",
      "   +- *(2) HashAggregate(keys=[Year#2098, Semester#2099], functions=[count(1), sum(cast(Credits#2101 as bigint))])\n",
      "      +- Exchange hashpartitioning(Year#2098, Semester#2099, 200), ENSURE_REQUIREMENTS, [id=#1489]\n",
      "         +- *(1) HashAggregate(keys=[Year#2098, Semester#2099], functions=[partial_count(1), partial_sum(cast(Credits#2101 as bigint))])\n",
      "            +- *(1) Project [_c0#2088 AS Year#2098, _c1#2089 AS Semester#2099, _c3#2091 AS Credits#2101]\n",
      "               +- *(1) Filter (isnotnull(_c0#2088) AND (_c0#2088 = 2016))\n",
      "                  +- FileScan csv [_c0#2088,_c1#2089,_c3#2091] Batched: false, DataFilters: [isnotnull(_c0#2088), (_c0#2088 = 2016)], Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/datasets/grades/fall2015.tsv, file:/home/jovyan/datasets/grad..., PartitionFilters: [], PushedFilters: [IsNotNull(_c0), EqualTo(_c0,2016)], ReadSchema: struct<_c0:int,_c1:string,_c3:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b7dcb2b7-cfaf-4e81-8f17-3c83981523b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Sort [Course#2100 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(Course#2100 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#1514]\n",
      "   +- *(1) Project [_c2#2090 AS Course#2100, _c3#2091 AS Credits#2101, _c4#2092 AS Grade#2102]\n",
      "      +- *(1) Filter (((isnotnull(_c1#2089) AND isnotnull(_c0#2088)) AND (_c1#2089 = Fall)) AND (_c0#2088 = 2016))\n",
      "         +- FileScan csv [_c0#2088,_c1#2089,_c2#2090,_c3#2091,_c4#2092] Batched: false, DataFilters: [isnotnull(_c1#2089), isnotnull(_c0#2088), (_c1#2089 = Fall), (_c0#2088 = 2016)], Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/datasets/grades/fall2015.tsv, file:/home/jovyan/datasets/grad..., PartitionFilters: [], PushedFilters: [IsNotNull(_c1), IsNotNull(_c0), EqualTo(_c1,Fall), EqualTo(_c0,2016)], ReadSchema: struct<_c0:int,_c1:string,_c2:string,_c3:int,_c4:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "b = grades.sort(\"Course\") \\\n",
    "    .filter(grades.Semester == \"Fall\")\\\n",
    "    .select(\"Course\", grades.Credits, grades[\"Grade\"])\\\n",
    "    .filter(\"year = 2016\")\n",
    "\n",
    "b.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4086c19f-0422-41ba-8aa8-fe22c0493c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Sort [Course#2100 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(Course#2100 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [id=#1514]\n",
      "   +- *(1) Project [_c2#2090 AS Course#2100, _c3#2091 AS Credits#2101, _c4#2092 AS Grade#2102]\n",
      "      +- *(1) Filter (((isnotnull(_c1#2089) AND isnotnull(_c0#2088)) AND (_c1#2089 = Fall)) AND (_c0#2088 = 2016))\n",
      "         +- FileScan csv [_c0#2088,_c1#2089,_c2#2090,_c3#2091,_c4#2092] Batched: false, DataFilters: [isnotnull(_c1#2089), isnotnull(_c0#2088), (_c1#2089 = Fall), (_c0#2088 = 2016)], Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/datasets/grades/fall2015.tsv, file:/home/jovyan/datasets/grad..., PartitionFilters: [], PushedFilters: [IsNotNull(_c1), IsNotNull(_c0), EqualTo(_c1,Fall), EqualTo(_c0,2016)], ReadSchema: struct<_c0:int,_c1:string,_c2:string,_c3:int,_c4:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = grades.filter(\"year = 2016\")\\\n",
    "    .filter(grades.Semester == \"Fall\")\\\n",
    "    .sort(\"Course\") \\\n",
    "    .select(\"Course\", grades.Credits, grades[\"Grade\"])\n",
    "b.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8cf6a79d-8eed-4618-aca5-6b2ce60bf17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = spark.read.json(\"file:///home/jovyan/datasets/json-samples/google-places.json\")\n",
    "c = spark.read.csv(\"file:///home/jovyan/datasets/customers/customers.csv\", inferSchema=True, header=True)\n",
    "s = spark.read.csv(\"file:///home/jovyan/datasets/customers/surveys.csv\",inferSchema=True, header=True)\n",
    "g = spark.read.csv(\"file:///home/jovyan/datasets/grades/*.tsv\",inferSchema=False, header=False, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "37728104-04db-4e08-aaf1-27293f2b60a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.createOrReplaceTempView(\"customers\")\n",
    "s.createOrReplaceTempView(\"surveys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "5b924419-e625-4db0-b409-79df13826f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------------------+------+---------------+--------+-----+------------+---------------+---------------+\n",
      "|First|  Last|             Email|Gender|Last IP Address|    City|State|Total Orders|Total Purchased|Months Customer|\n",
      "+-----+------+------------------+------+---------------+--------+-----+------------+---------------+---------------+\n",
      "|   Al|Fresco|afresco@dayrep.com|     M|  74.111.18.161|Syracuse|   NY|           1|             45|              1|\n",
      "+-----+------+------------------+------+---------------+--------+-----+------------+---------------+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from customers\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0d5f141a-aa07-43e6-b260-47657ee41f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------------------+------+---------------+--------+-----+------------+---------------+---------------+\n",
      "|First|  Last|             Email|Gender|Last IP Address|    City|State|Total Orders|Total Purchased|Months Customer|\n",
      "+-----+------+------------------+------+---------------+--------+-----+------------+---------------+---------------+\n",
      "|   Al|Fresco|afresco@dayrep.com|     M|  74.111.18.161|Syracuse|   NY|           1|             45|              1|\n",
      "+-----+------+------------------+------+---------------+--------+-----+------------+---------------+---------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cb15abd6-eeff-4f63-a4e9-a93592d10847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+---------------+--------+--------------------+\n",
      "|               Email|Gender|State|Months Customer|Own Home|    Household Income|\n",
      "+--------------------+------+-----+---------------+--------+--------------------+\n",
      "|etasomthin@superr...|     M|   NY|             28|      No|               39000|\n",
      "|   jpoole@dayrep.com|     F|   NY|             12|     Yes|Prefer not to Answer|\n",
      "| ojouglad@einrot.com|     M|   NY|             36|      No|               65000|\n",
      "| rovlight@dayrep.com|     M|   NY|             42|      No|               28000|\n",
      "| sladd@superrito.com|     M|   NY|             10|     Yes|               52000|\n",
      "+--------------------+------+-----+---------------+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select c.Email, c.Gender, c.State, c.`Months Customer`, s.`Own Home`, s.`Household Income`\n",
    "from customers c left join surveys s on \n",
    "        c.Email = s.Email\n",
    "    where c.State = 'NY'\n",
    "    and c.`Months Customer` > 5\n",
    "    and s.`Own Home` is not null\n",
    "'''\n",
    "nybigwigs = spark.sql(query)\n",
    "nybigwigs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "41a2a846-8362-4a15-a75b-93683d5dd0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nybigwigs.createOrReplaceTempView(\"v_nybigwigs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "7c07e5d8-8cb1-452e-97ca-464f53a2a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mailinglist = spark.sql(\"select Email, Gender, `Own Home` from v_nybigwigs where `Own Home` = 'Yes'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4dbe714b-edc7-49c0-ad35-05db474043b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Project [Email#2193, Gender#2194, Own Home#2231]\n",
      "+- *(2) BroadcastHashJoin [Email#2193], [Email#2227], Inner, BuildLeft, false\n",
      "   :- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [id=#1920]\n",
      "   :  +- *(1) Project [Email#2193, Gender#2194]\n",
      "   :     +- *(1) Filter ((((isnotnull(State#2197) AND isnotnull(Months Customer#2200)) AND (State#2197 = NY)) AND (Months Customer#2200 > 5)) AND isnotnull(Email#2193))\n",
      "   :        +- FileScan csv [Email#2193,Gender#2194,State#2197,Months Customer#2200] Batched: false, DataFilters: [isnotnull(State#2197), isnotnull(Months Customer#2200), (State#2197 = NY), (Months Customer#2200..., Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/datasets/customers/customers.csv], PartitionFilters: [], PushedFilters: [IsNotNull(State), IsNotNull(Months Customer), EqualTo(State,NY), GreaterThan(Months Customer,5),..., ReadSchema: struct<Email:string,Gender:string,State:string,Months Customer:int>\n",
      "   +- *(2) Filter ((isnotnull(Own Home#2231) AND (Own Home#2231 = Yes)) AND isnotnull(Email#2227))\n",
      "      +- FileScan csv [Email#2227,Own Home#2231] Batched: false, DataFilters: [isnotnull(Own Home#2231), (Own Home#2231 = Yes), isnotnull(Email#2227)], Format: CSV, Location: InMemoryFileIndex[file:/home/jovyan/datasets/customers/surveys.csv], PartitionFilters: [], PushedFilters: [IsNotNull(Own Home), EqualTo(Own Home,Yes), IsNotNull(Email)], ReadSchema: struct<Email:string,Own Home:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mailinglist.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4d07cc61-e23f-4cec-8b44-2a7e20d8901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|               Email|        upper(Email)|Gender|\n",
      "+--------------------+--------------------+------+\n",
      "|etasomthin@superr...|ETASOMTHIN@SUPERR...|     M|\n",
      "|   jpoole@dayrep.com|   JPOOLE@DAYREP.COM|     F|\n",
      "| ojouglad@einrot.com| OJOUGLAD@EINROT.COM|     M|\n",
      "| rovlight@dayrep.com| ROVLIGHT@DAYREP.COM|     M|\n",
      "| sladd@superrito.com| SLADD@SUPERRITO.COM|     M|\n",
      "+--------------------+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import * \n",
    "\n",
    "@udf(returnType=StringType()) \n",
    "def upperCase(str):\n",
    "    return str.upper()\n",
    "\n",
    "# This is different!!!!!\n",
    "spark.udf.register(\"upper\", upperCase)\n",
    "\n",
    "spark.sql(\"select Email, upper(Email), Gender from v_nybigwigs\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db2e2c3-8870-42ef-b5d9-661f32dd215f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab411b2-cb99-4fb9-b0e6-04036ba041b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c6113-22e1-4dfd-b4a3-eb61e9540683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ae450f-9c3c-45f7-abaa-ffac9afcc86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "mongo_uri = \"mongodb://admin:mongopw@mongo:27017/admin?authSource=admin\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "      .config(\"spark.mongodb.input.uri\", mongo_uri) \\\n",
    "      .config(\"spark.mongodb.output.uri\", mongo_uri) \\\n",
    "      .config(\"spark.jars.packages\",\"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\")\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e842b4-dcc7-4da5-be23-48dcd1bcb4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- alpha2Code: string (nullable = true)\n",
      " |-- alpha3Code: string (nullable = true)\n",
      " |-- altSpellings: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- area: double (nullable = true)\n",
      " |-- borders: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- callingCodes: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- capital: string (nullable = true)\n",
      " |-- currencies: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- demonym: string (nullable = true)\n",
      " |-- gini: double (nullable = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- latlng: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- nativeName: string (nullable = true)\n",
      " |-- numericCode: string (nullable = true)\n",
      " |-- population: long (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      " |-- relevance: string (nullable = true)\n",
      " |-- subregion: string (nullable = true)\n",
      " |-- timezones: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- topLevelDomain: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- translations: struct (nullable = true)\n",
      " |    |-- de: string (nullable = true)\n",
      " |    |-- es: string (nullable = true)\n",
      " |    |-- fr: string (nullable = true)\n",
      " |    |-- it: string (nullable = true)\n",
      " |    |-- ja: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e = spark.read.format(\"mongo\").option(\"database\",\"demo\").option(\"collection\",\"europe\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c291edeb-7ba1-4ff4-9600-9bf51885d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "mongoq = e.select(\"alpha3Code\", \"name\",\"subregion\", \"population\", \n",
    "                  explode(col(\"borders\")).alias(\"borderAlpha3Code\")) \\\n",
    "    .filter(\"subregion = 'Northern Europe'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d0f7038-15ce-4b59-a8da-c4ba91d8285d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) Project [alpha3Code#2, name#13, subregion#19, population#16L, borderAlpha3Code#170]\n",
      "+- Generate explode(borders#5), [alpha3Code#2, name#13, population#16L, subregion#19], false, [borderAlpha3Code#170]\n",
      "   +- *(1) Filter ((((size(borders#5, true) > 0) AND isnotnull(subregion#19)) AND (subregion#19 = Northern Europe)) AND isnotnull(borders#5))\n",
      "      +- *(1) Scan MongoRelation(MongoRDD[0] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true), StructField(alpha2Code,StringType,true), StructField(alpha3Code,StringType,true), StructField(altSpellings,ArrayType(StringType,true),true), StructField(area,DoubleType,true), StructField(borders,ArrayType(StringType,true),true), StructField(callingCodes,ArrayType(StringType,true),true), StructField(capital,StringType,true), StructField(currencies,ArrayType(StringType,true),true), StructField(demonym,StringType,true), StructField(gini,DoubleType,true), StructField(languages,ArrayType(StringType,true),true), StructField(latlng,ArrayType(DoubleType,true),true), StructField(name,StringType,true), StructField(nativeName,StringType,true), StructField(numericCode,StringType,true), StructField(population,LongType,true), StructField(region,StringType,true), StructField(relevance,StringType,true), StructField(subregion,StringType,true), StructField(timezones,ArrayType(StringType,true),true), StructField(topLevelDomain,ArrayType(StringType,true),true), StructField(translations,StructType(StructField(de,StringType,true), StructField(es,StringType,true), StructField(fr,StringType,true), StructField(it,StringType,true), StructField(ja,StringType,true)),true)))) [alpha3Code#2,borders#5,name#13,population#16L,subregion#19] PushedFilters: [IsNotNull(subregion), EqualTo(subregion,Northern Europe), IsNotNull(borders)], ReadSchema: struct<alpha3Code:string,borders:array<string>,name:string,population:bigint,subregion:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mongoq.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e557ea7-f676-461a-84cc-409a0fab4a74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_62/346291715.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef211490-9075-4171-82a5-131e175faaf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eb6afe1-b4e6-4427-a032-6ebb837c8841",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = spark.read.option(\"multiline\",\"true\").json(\"file:///home/jovyan/datasets/json-samples/stocks.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "935ae9cf-ad45-43f4-b238-659993b9d226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|  price|symbol|\n",
      "+-------+------+\n",
      "| 126.82|  AAPL|\n",
      "|3098.12|  AMZN|\n",
      "| 251.11|    FB|\n",
      "|1725.05|  GOOG|\n",
      "| 128.39|   IBM|\n",
      "| 212.55|  MSFT|\n",
      "|   78.0|   NET|\n",
      "|  497.0|  NFLX|\n",
      "|  823.8|  TSLA|\n",
      "|  45.11|  TWTR|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stocks.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce09a6c9-d204-455e-a976-b80b4c6dd63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks.write.format(\"mongo\") \\\n",
    "    .mode(\"overwrite\").option(\"database\",\"fdoc\")\\\n",
    "    .option(\"collection\",\"stocks1\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4af2997f-f492-451e-bd2f-4e732cc8df08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+------+\n",
      "|                 _id|  price|symbol|\n",
      "+--------------------+-------+------+\n",
      "|{6245c34eb2942b6c...| 126.82|  AAPL|\n",
      "|{6245c34eb2942b6c...|3098.12|  AMZN|\n",
      "|{6245c34eb2942b6c...| 251.11|    FB|\n",
      "|{6245c34eb2942b6c...|1725.05|  GOOG|\n",
      "|{6245c34eb2942b6c...| 128.39|   IBM|\n",
      "|{6245c34eb2942b6c...| 212.55|  MSFT|\n",
      "|{6245c34eb2942b6c...|   78.0|   NET|\n",
      "|{6245c34eb2942b6c...|  497.0|  NFLX|\n",
      "|{6245c34eb2942b6c...|  823.8|  TSLA|\n",
      "|{6245c34eb2942b6c...|  45.11|  TWTR|\n",
      "+--------------------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"mongo\") \\\n",
    "    .option(\"database\",\"fdoc\")\\\n",
    "    .option(\"collection\",\"stocks1\").load().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad3b8e7c-77b8-4d33-9e3a-bbff145b999d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----+\n",
      "|  price|symbol| _id|\n",
      "+-------+------+----+\n",
      "| 126.82|  AAPL|AAPL|\n",
      "|3098.12|  AMZN|AMZN|\n",
      "| 251.11|    FB|  FB|\n",
      "|1725.05|  GOOG|GOOG|\n",
      "| 128.39|   IBM| IBM|\n",
      "| 212.55|  MSFT|MSFT|\n",
      "|   78.0|   NET| NET|\n",
      "|  497.0|  NFLX|NFLX|\n",
      "|  823.8|  TSLA|TSLA|\n",
      "|  45.11|  TWTR|TWTR|\n",
      "+-------+------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stocks2 = stocks.withColumn(\"_id\", stocks.symbol)\n",
    "stocks2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a77774d4-e800-43fd-b00b-97e607f18aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks2.write.format(\"mongo\") \\\n",
    "    .mode(\"overwrite\").option(\"database\",\"fdoc\")\\\n",
    "    .option(\"collection\",\"stocks2\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f2dc36f-f728-4b6a-ab1e-d5d2a1d807b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+------+\n",
      "| _id|  price|symbol|\n",
      "+----+-------+------+\n",
      "|AAPL| 126.82|  AAPL|\n",
      "|AMZN|3098.12|  AMZN|\n",
      "|  FB| 251.11|    FB|\n",
      "|GOOG|1725.05|  GOOG|\n",
      "| IBM| 128.39|   IBM|\n",
      "|MSFT| 212.55|  MSFT|\n",
      "| NET|   78.0|   NET|\n",
      "|NFLX|  497.0|  NFLX|\n",
      "|TSLA|  823.8|  TSLA|\n",
      "|TWTR|  45.11|  TWTR|\n",
      "+----+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"mongo\") \\\n",
    "    .option(\"database\",\"fdoc\")\\\n",
    "    .option(\"collection\",\"stocks2\").load().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d8475-ac67-4eee-846f-b89d4b54a506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b75087b-8511-458a-938f-ddb5b1a8ed3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f5d70b6-ff86-4921-acb0-a41009197546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "# CASSANDRA CONFIGURATION\n",
    "cassandra_host = \"cassandra\"\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "      .config(\"spark.cassandra.connection.host\", cassandra_host) \\\n",
    "      .config(\"spark.jars.packages\",\"com.datastax.spark:spark-cassandra-connector-assembly_2.12:3.1.0\")\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5156dd6e-2930-47da-a70d-b5eb9f3f2bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# WE NEED A TABLE BEFORE WE CAN WRITE, Using Plain old Python\n",
    "!pip install -q cassandra-driver\n",
    "from cassandra.cluster import Cluster\n",
    "with Cluster([cassandra_host]) as cluster:\n",
    "    session = cluster.connect()\n",
    "    session.execute(\"CREATE KEYSPACE IF NOT EXISTS gdemo WITH replication={ 'class': 'SimpleStrategy', 'replication_factor' : 1 };\")\n",
    "    table = '''\n",
    "    CREATE TABLE IF NOT EXISTS gdemo.fudgemart_order_details (\n",
    "        customer_id int,\n",
    "        customer_email text,\n",
    "        customer_name text,\n",
    "        customer_address text,\n",
    "        customer_city text,\n",
    "        customer_state text,\n",
    "        customer_zip text,\n",
    "        order_id int,\n",
    "        order_date date,\n",
    "        creditcard_number text,\n",
    "        creditcard_exp_date text, \n",
    "        order_total decimal ,\n",
    "        ship_via text,\n",
    "        shipped_date date,\n",
    "        product_id int,\n",
    "        order_item_id int,\n",
    "        order_qty int,\n",
    "        product_name text,\n",
    "        product_retail_price decimal,\n",
    "    primary key ((customer_id, order_id), order_item_id) \n",
    "    );\n",
    "    '''\n",
    "    session.execute(table)\n",
    "\n",
    "# NOTE: CSV File format does not understand dates, but Cassandra does, so we must cast the string columns to date before loading into the table\n",
    "od = spark.read.option(\"inferSchema\",True).option(\"header\",True).csv(\"file:///home/jovyan/datasets/fudgemart/fudgemart-order-details.csv\")\\\n",
    "    .withColumn(\"order_date\", col(\"order_date\").cast(\"date\")).withColumn(\"shipped_date\", col(\"shipped_date\").cast(\"date\")) \n",
    "    \n",
    "od.write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "  .mode(\"Append\")\\\n",
    "  .option(\"table\", \"fudgemart_order_details\")\\\n",
    "  .option(\"keyspace\",\"gdemo\")\\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b273a3a-9776-45f0-8ef3-d620ae8033f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo =spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "    .options(table=\"fudgemart_order_details\", keyspace=\"gdemo\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e86215-95ae-4b4a-bbe2-d1edd2c38fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [customer_id#151, order_id#152, order_item_id#153]\n",
      "+- BatchScan[customer_id#151, order_id#152, order_item_id#153] Cassandra Scan: gdemo.fudgemart_order_details\n",
      " - Cassandra Filters: [[\"customer_id\" = ?, 13],[\"order_id\" = ?, 1843]]\n",
      " - Requested Columns: [customer_id,order_id,order_item_id]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fo.select(\"customer_id\",\"order_id\",\"order_item_id\").where(\"customer_id=13 and order_id=1843\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "956fa989-c4bf-4201-9fec-e587cf4ecd2b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Filter (ship_via#168 = Postal Service)\n",
      "+- BatchScan[customer_id#151, order_id#152, order_item_id#153, ship_via#168] Cassandra Scan: gdemo.fudgemart_order_details\n",
      " - Cassandra Filters: []\n",
      " - Requested Columns: [customer_id,order_id,order_item_id,ship_via]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fo.select(\"customer_id\",\"order_id\",\"order_item_id\", \"ship_via\").where(\"ship_via='Postal Service'\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416f7f25-d85d-4b4e-9734-18a2d0039b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917833dd-856f-4c50-8406-67774b06f7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32434c7-1411-414f-8417-d6e29b471618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffde2d3-8b08-42fa-99fe-1b55c4ff69bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f340a8-7e48-408a-9e1e-e5b17da806f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9c02e38-08ae-47b5-8cbc-069ab1d0dba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# REDIS CONFIGURATION\n",
    "redis_host = \"redis\"\n",
    "redis_port = \"6379\"\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "      .config(\"spark.redis.host\", redis_host)\\\n",
    "      .config(\"spark.redis.port\", redis_port)\\\n",
    "      .config(\"spark.jars.packages\",\"com.redislabs:spark-redis_2.12:3.0.0\")\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "836cc625-6e23-4953-91e5-6dcf8ccb22f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126.82</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3098.12</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>251.11</td>\n",
       "      <td>FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1725.05</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128.39</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>212.55</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>78.00</td>\n",
       "      <td>NET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>497.00</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>823.80</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>45.11</td>\n",
       "      <td>TWTR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     price symbol\n",
       "0   126.82   AAPL\n",
       "1  3098.12   AMZN\n",
       "2   251.11     FB\n",
       "3  1725.05   GOOG\n",
       "4   128.39    IBM\n",
       "5   212.55   MSFT\n",
       "6    78.00    NET\n",
       "7   497.00   NFLX\n",
       "8   823.80   TSLA\n",
       "9    45.11   TWTR"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.option(\"multiline\",\"true\").json(\"/home/jovyan/datasets/json-samples/stocks.json\")\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2d198ce-fac3-468a-85d0-8f0c3d8c02ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"org.apache.spark.sql.redis\")\\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"table\", \"stocks\") \\\n",
    "    .option(\"key.column\",\"symbol\").save()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e9d0935-18e8-4a5a-835e-e97d24d5e02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = spark.read.format(\"org.apache.spark.sql.redis\") \\\n",
    "    .option(\"keys.pattern\",\"post:*\") \\\n",
    "    .option(\"key.column\",\"post_id\") \\\n",
    "    .option(\"infer.schema\", True) \\\n",
    "    .load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40322816-0ffa-4128-b72e-8dd003ef8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = spark.read.format(\"org.apache.spark.sql.redis\") \\\n",
    "    .option(\"keys.pattern\",\"user:*\") \\\n",
    "    .option(\"key.column\",\"userid\") \\\n",
    "    .option(\"infer.schema\", True) \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf63895-f475-4c03-8f1f-1bd8e0cffe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------+------+--------------------+-------+----------+-------+\n",
      "|                auth|password|username|userid|                body|user_id|      time|post_id|\n",
      "+--------------------+--------+--------+------+--------------------+-------+----------+-------+\n",
      "|5651e84b11d8fdabf...| testing|    mike|     1|        I am hungry!|      1|1648825104|      1|\n",
      "|5651e84b11d8fdabf...| testing|    mike|     1|Working on some i...|      1|1648825124|      2|\n",
      "|3c04b13163cbb4230...| testing|   alice|     2|   I am also hungry!|      2|1648825475|      3|\n",
      "+--------------------+--------+--------+------+--------------------+-------+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.join(posts, users.userid == posts.user_id, \"inner\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a91833bf-0620-408c-880b-e0eb028db787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) SortMergeJoin [userid#49], [user_id#14], Inner\n",
      ":- *(2) Sort [userid#49 ASC NULLS FIRST], false, 0\n",
      ":  +- Exchange hashpartitioning(userid#49, 200), ENSURE_REQUIREMENTS, [id=#95]\n",
      ":     +- *(1) Filter isnotnull(userid#49)\n",
      ":        +- *(1) Scan org.apache.spark.sql.redis.RedisSourceRelation@1e26ca0b [auth#46,password#47,username#48,userid#49] PushedFilters: [IsNotNull(userid)], ReadSchema: struct<auth:string,password:string,username:string,userid:string>\n",
      "+- *(4) Sort [user_id#14 ASC NULLS FIRST], false, 0\n",
      "   +- Exchange hashpartitioning(user_id#14, 200), ENSURE_REQUIREMENTS, [id=#101]\n",
      "      +- *(3) Filter isnotnull(user_id#14)\n",
      "         +- *(3) Scan org.apache.spark.sql.redis.RedisSourceRelation@30482432 [body#13,user_id#14,time#15,post_id#16] PushedFilters: [IsNotNull(user_id)], ReadSchema: struct<body:string,user_id:string,time:string,post_id:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users.join(posts, users.userid == posts.user_id, \"inner\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8890aa-4871-499d-aa8f-ab3a524391c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo cp /home/jovyan/work/jars/neo4j-connector-apache-spark_2.12-4.1.0_for_spark_3.jar /usr/local/spark/jars/neo4j-connector-apache-spark_2.12-4.1.0_for_spark_3.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fcee4de-8809-4fd7-b061-3ad7653695f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# NEO4J  CONFIGURATION\n",
    "bolt_url = \"bolt://neo4j:7687\"\n",
    "# Spark init\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c31e66fe-fc03-41b8-a98d-e92bff37d9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>facname</th>\n",
       "      <th>factitle</th>\n",
       "      <th>course</th>\n",
       "      <th>level</th>\n",
       "      <th>taught</th>\n",
       "      <th>is_por</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mike</td>\n",
       "      <td>PoP</td>\n",
       "      <td>IST256</td>\n",
       "      <td>UGrad</td>\n",
       "      <td>Fall2021</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mike</td>\n",
       "      <td>PoP</td>\n",
       "      <td>IST659</td>\n",
       "      <td>Grad</td>\n",
       "      <td>Spring2021</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mike</td>\n",
       "      <td>PoP</td>\n",
       "      <td>IST769</td>\n",
       "      <td>Grad</td>\n",
       "      <td>Fall2021</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jill</td>\n",
       "      <td>Adjunct</td>\n",
       "      <td>IST659</td>\n",
       "      <td>Grad</td>\n",
       "      <td>Fall2021</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  facname factitle  course  level      taught  is_por\n",
       "0    Mike      PoP  IST256  UGrad    Fall2021   False\n",
       "1    Mike      PoP  IST659   Grad  Spring2021    True\n",
       "2    Mike      PoP  IST769   Grad    Fall2021   False\n",
       "3    Jill  Adjunct  IST659   Grad    Fall2021   False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"facname\",\"factitle\",\"course\",\"level\",\"taught\", \"is_por\"]\n",
    "data = [('Mike','PoP', \"IST256\", \"UGrad\",\"Fall2021\",False),('Mike','PoP', \"IST659\", \"Grad\",\"Spring2021\",True),('Mike','PoP', \"IST769\", \"Grad\",\"Fall2021\",False), ('Jill','Adjunct', \"IST659\", \"Grad\",\"Fall2021\",False)]\n",
    "profs = spark.createDataFrame(data = data, schema = cols)\n",
    "profs.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d29130b-ab81-413b-b911-2c4b3788d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cipher_ql = '''\n",
    "MATCH (c:Courses {code: event.course}), (f:Faculty {name: event.facname})\n",
    "MERGE (f)-[:PROFESSOR_OF_RECORD]->(c)\n",
    "'''\n",
    "profs.where(\"is_por\").write.format(\"org.neo4j.spark.DataSource\").mode(\"Overwrite\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"query\",cipher_ql) \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b967223d-4116-4cb3-a79d-7f1a49d72ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cypher_ql = '''\n",
    "MATCH (c:Courses {code: event.course}), (f:Faculty {name: event.facname})\n",
    "MERGE (f)-[:TEACHES {semester: event.taught}]->(c)\n",
    "'''\n",
    "profs.write.format(\"org.neo4j.spark.DataSource\").mode(\"Overwrite\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"query\",cypher_ql) \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa9d4bd4-1f6f-4d6b-a279-fa6a48bb2c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cypher_ql = \"MERGE (c:Courses {code: event.course, level: event.level })\"\n",
    "profs.select(\"course\",\"level\").distinct().write.format(\"org.neo4j.spark.DataSource\").mode(\"Overwrite\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"query\",cypher_ql) \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f71e35a-2ccb-4f7b-8671-ac7a9d8fa4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Faculty\n",
    "f = profs.select(\"facname\",\"factitle\").distinct()\n",
    "cypher_ql = \"MERGE (f:Faculty {name : event.facname, title: event.factitle})\"\n",
    "\n",
    "f.write.format(\"org.neo4j.spark.DataSource\").mode(\"Overwrite\") \\\n",
    "  .option(\"url\", bolt_url) \\\n",
    "  .option(\"query\",cypher_ql) \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2251235-201f-4473-9746-0992577bdbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a568007-ecb3-439c-9d56-5b8e1b3ee3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff7f17e-0fe5-45a9-9ead-3e3e98b8868e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeea6dc-9469-451b-8389-cb7dae5122eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
