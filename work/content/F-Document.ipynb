{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6cac071-f24a-48a9-b639-0501372a313d",
   "metadata": {},
   "source": [
    "# Unit F\n",
    "# Document Database Model\n",
    "\n",
    "- Examples From Video Lecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d793ae9-eaed-4ff6-a116-fea3dcdb9421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark init\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "mongo_uri = \"mongodb://admin:mongopw@mongo:27017/admin?authSource=admin\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "      .config(\"spark.mongodb.input.uri\", mongo_uri) \\\n",
    "      .config(\"spark.mongodb.output.uri\", mongo_uri) \\\n",
    "      .config(\"spark.jars.packages\",\"org.mongodb.spark:mongo-spark-connector_2.12:3.0.2\")\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bea940f-06cb-4972-879b-341283300864",
   "metadata": {},
   "source": [
    "## Loading Sample Data\n",
    "\n",
    "- Run this code to load some sample data into MongoDb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27450bc0-b2cd-4186-b18b-861effba8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Sample Data\n",
    "from pyspark.sql.functions import col\n",
    "s = spark.read.option(\"multiline\",\"true\").json(\"file:///home/jovyan/datasets/json-samples/stocks.json\")\n",
    "spark.read.option(\"multiline\",\"true\").json(\"file:///home/jovyan/datasets/json-samples/Europe.json\")\\\n",
    "    .write.format(\"mongo\").mode(\"overwrite\").option(\"database\",\"demo\").option(\"collection\",\"europe\").save()\n",
    "spark.read.option(\"multiline\",\"true\").json(\"file:///home/jovyan/datasets/json-samples/fudgemart-products.json\")\\\n",
    "    .withColumn(\"_id\", col(\"product_id\")).write.format(\"mongo\").mode(\"overwrite\").option(\"database\",\"demo\").option(\"collection\",\"products\").save()\n",
    "spark.read.option(\"multiline\",\"true\").json(\"file:///home/jovyan/datasets/json-samples/US-Senators.json\")\\\n",
    "    .write.format(\"mongo\").mode(\"overwrite\").option(\"database\",\"demo\").option(\"collection\",\"senators\").save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07928d9-49b9-4e6d-97b4-2f87795aef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"multiline\",\"true\").json(\"file:///home/jovyan/datasets/json-samples/Europe.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839e5043-9c6c-47c2-9db2-0aa790a3301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"mongo\").mode(\"overwrite\")\\\n",
    "    .option(\"database\",\"demo\")\\\n",
    "    .option(\"collection\",\"europe\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eedccf86-20cd-4340-ad10-ee93d6ce8bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmp = spark.read.option(\"multiline\",\"true\")\\\n",
    ".json(\"file:///home/jovyan/datasets/json-samples/fudgemart-products.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb8e312b-69d6-4507-8297-4037a3f1b812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+--------------------+--------------------+-----------+--------------------+\n",
      "|product_category|product_id|        product_name|product_retail_price|vendor_name|      vendor_website|\n",
      "+----------------+----------+--------------------+--------------------+-----------+--------------------+\n",
      "|        Hardware|         1|Straight Claw Hammer|               15.95|    Stanlee|                NULL|\n",
      "|        Hardware|         2|       Sledge Hammer|               21.95|    Stanlee|                NULL|\n",
      "|        Hardware|         3|     Rip Claw Hammer|               19.95|    Stanlee|                NULL|\n",
      "|        Clothing|         4|         Dri-Fit Tee|                20.0|      Mikey|    http://mikee.com|\n",
      "|        Clothing|         5|       Running Pants|                35.0|      Mikey|    http://mikee.com|\n",
      "|        Clothing|         6|          Wool Socks|                 8.0|      Mikey|    http://mikee.com|\n",
      "|        Clothing|         7|      Squeaky Sneaks|                65.0|      Mikey|    http://mikee.com|\n",
      "|        Clothing|         8|          Cool Jeans|                45.0|  Leaveeyes|                NULL|\n",
      "|        Clothing|         9|        Denim Jacket|                60.0|  Leaveeyes|                NULL|\n",
      "|        Clothing|        10|      Leather Jacket|                95.0|  Leaveeyes|                NULL|\n",
      "|        Clothing|        11|      Courdory Pants|                24.0|  Leaveeyes|                NULL|\n",
      "|        Clothing|        12|          Work Pants|                38.0|    Stanlee|                NULL|\n",
      "|        Clothing|        13|         Work Gloves|                 8.0|    Stanlee|                NULL|\n",
      "|        Clothing|        14|      Comfor-fit Tee|                12.0|    Weebock|http://www.weeboc...|\n",
      "|        Clothing|        15|      Running Shorts|                20.0|    Weebock|http://www.weeboc...|\n",
      "|        Clothing|        16|       X-Train Shoes|                75.0|    Weebock|http://www.weeboc...|\n",
      "|        Clothing|        17|        Baseball Cap|                10.0|    Weebock|http://www.weeboc...|\n",
      "|     Electronics|        18|          DVD Player|                45.0|      Soney|http://www.soney.com|\n",
      "|     Electronics|        19|       HD-DVD Player|               150.0|      Soney|http://www.soney.com|\n",
      "|     Electronics|        20|  Blu-Ray DVD Player|               150.0|      Soney|http://www.soney.com|\n",
      "+----------------+----------+--------------------+--------------------+-----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fmp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c68a40-cb75-49c9-af6c-f56bdbbbb53b",
   "metadata": {},
   "source": [
    "## MongoDB Clients and Applications:\n",
    "\n",
    "- The **Mongo Db Shell** is the offical client where you can type in the MQL (Mongo Query Language)  \n",
    "  `PS> docker-compose exec mongo mongosh -u admin -p mongopw --authenticationDatabase=admin`\n",
    "- **Mongo Express** is a web-based database administration application, http://localhost:8881\n",
    "- There is a **Sample Python Application** here: http://localhost:5081\n",
    "- To Connect MongoDb to Tools like Tableau or PowerBI, use an ODBC driver like this one here:  \n",
    "  https://github.com/mongodb/mongo-bi-connector-odbc-driver/releases/\n",
    "  \n",
    "  \n",
    "## Mongo Shell Queries\n",
    "\n",
    "\n",
    "### MQL: Create and Read\n",
    "\n",
    "```\n",
    "# current Database \n",
    "db\n",
    "\n",
    "# Show all databases\n",
    "show databases\n",
    "\n",
    "\n",
    "# Use a database, does not have to exist - mongo don't care!\n",
    "use demo\n",
    "\n",
    "#show collections \n",
    "show collections\n",
    "\n",
    "# insert some data – how did it make the collection – mongo don’t care!\n",
    "db.cars.insertOne({ \"make\": \"Chevy\", \"model\" : \"Cruze\" })\n",
    "\n",
    "# insert a couple....\n",
    "db.cars.insertMany( [ { \"make\": \"Chevy\", \"model\" : \"Traverse\" }, { \"make\": \"Chevy\", \"model\" : \"Trax\", \"mpg\" : 36} ] )\n",
    "\n",
    "# show all documents\n",
    "db.cars.find()\n",
    "\n",
    "# No a car? Mongo don't care!\n",
    "db.cars.insertOne( { \"name\" : \"Mike Fudge\", \"age\" : 50 } )\n",
    "db.cars.find()\n",
    "\n",
    "\n",
    "# Insert same thing twice … mongo don’t care!\n",
    "db.cars.insertOne({ \"make\": \"Honda\", \"model\" : \"Civic\"})\n",
    "\n",
    "# oops no schema but I forgot mpg...\n",
    "db.cars.insertOne({ \"make\": \"Honda\", \"model\" : \"Civic\", \"mpg\" : 40 })\n",
    "\n",
    "## Simple query By Value\n",
    "\n",
    "db.cars.find( { \"make\" : \"Chevy\" })\n",
    "\n",
    "```\n",
    "\n",
    "### MQL:Understanding_id\n",
    "\n",
    "```\n",
    "# Insert Multiple Times \n",
    "\n",
    "db.cars.insertOne( { \"make\" : \"Honda\", \"model\" : \"CRV\"})\n",
    "db.cars.insertOne( { \"make\" : \"Honda\", \"model\" : \"CRV\"})\n",
    "\n",
    "# added once\n",
    "db.cars.insertOne( { \"make\" : \"Honda\", \"model\" : \"CRV\", \"_id\" : 1 })\n",
    "\n",
    "# cannot be added again! At least there is key integrity.\n",
    "db.cars.insertOne( { \"make\" : \"Honda\", \"model\" : \"CRV\", \"_id\" : 1 })\n",
    "```\n",
    "\n",
    "### MQL: Updating and Deleting Data\n",
    "\n",
    "\n",
    "```\n",
    "# delete the first one that matches \n",
    "db.cars.deleteOne( { \"model\" : \"CRV\" } )\n",
    "\n",
    "bb.cars.find()\n",
    "\n",
    "# delete all that match\n",
    "db.cars.deleteMany( { \"model\" : \"CRV\" } )\n",
    "\n",
    "# delete something that's not there\n",
    "db.cars.deleteMany( { \"model\" : \"Fabio\" })\n",
    "\n",
    "# delete by Object Id\n",
    "db.cars.find({ \"name\" : \"Mike Fudge\" })\n",
    "(record object ID)\n",
    "db.cars.deleteOne({\"_id\" : ObjectId(\"6203d8c48017a5f57d121bf6\")})\n",
    "\n",
    "# delete by an object ID, Non Surrogate\n",
    "db.cars.deletOne( { \"_id\" : 1 } )\n",
    "\n",
    "# replace – no partial updates\n",
    "db.cars.insertOne( { \"make\" : \"Honda\", \"model\" : \"CRV\", \"_id\" : 2 })\n",
    "\n",
    "db.cars.replaceOne({ \"_id\" : 2},  { \"mpg\" : 26 } )\n",
    "\n",
    "#where did it go?\n",
    "bb.cars.find()\n",
    "\n",
    "# full overwrite, so you must replace\n",
    "db.cars.replaceOne({ \"_id\" : 2},  { \"make\" : \"Honda\", \"model\" : \"CRV\", \"mpg\": 26, \"_id\" : 2 })\n",
    "\n",
    "\n",
    "# updates - add MPG to traverse\n",
    "\n",
    "db.cars.updateOne({model: 'Traverse'}, {$set : {mpg:18}})\n",
    "\n",
    "# update multiple values\n",
    "db.cars.updateOne({model: 'Traverse'}, {$set : {mpg:16, \"type\": \"SUV\" }})\n",
    "\n",
    "#update several documents\n",
    "\n",
    "db.cars.updateMany({}, { $set: { \"owner\": \"mafudge\"}} )\n",
    "\n",
    "```\n",
    "\n",
    "### Find Queries\n",
    "\n",
    "```\n",
    "# no filter,  just ask for 3 columns (notice we get nothing for license plate)\n",
    "\n",
    "db.cars({}, { make:1, model:2, \"license place\":3 }) \n",
    "\n",
    "# here's a complex filter: make is chevy and includes an mpg\n",
    "db.cars.find({ $and : [  {make : \"Chevy\"}, {mpg : { $exists: true } } ] })\n",
    "\n",
    "# let's combine that:\n",
    "db.cars.find({ $and : [  {make : \"Chevy\"}, {mpg : { $exists: true } } ] }, { make:1, model:2, mpg:3, \"license place\":6 })\n",
    "\n",
    "#and let's sort that\n",
    "db.cars.find({ $and : [  {make : \"Chevy\"}, {mpg : { $exists: true } } ] }, { make:1, model:2, mpg:3, \"license place\":6 }).sort({mpg:-1})\n",
    "\n",
    "```\n",
    "\n",
    "### Indexing\n",
    "\n",
    "\n",
    "```\n",
    "# querying by region!\n",
    "db.europe.find( {\"subregion\" : \"Eastern Europe\"}).explain(\"executionStats\")\n",
    "\n",
    "Seaches through all 53 countries…. Blah. (docsExamined)\n",
    "COLLSCAN is like a TABLE SCAN in SQL\n",
    "\n",
    "# Let’s add an index.\n",
    "db.europe.createIndex( {subregion:1})\n",
    "\n",
    "db.europe.find( {\"subregion\" : \"Eastern Europe\"}).explain(\"executionStats\")\n",
    "db.europe.find( {\"subregion\" : “Southern Europe\"}).explain(\"executionStats\")\n",
    "\n",
    "Now its doing an IXSCAN (index scan) and looking at the keysExamined!\n",
    "```\n",
    "\n",
    "## Drilling Mongo\n",
    "\n",
    "```\n",
    "\n",
    "Storage config is easy!\n",
    "\n",
    "{\n",
    "  \"type\": \"mongo\",\n",
    "  \"connection\": \"mongodb://admin:mongopw@mongo:27017/admin\",\n",
    "  \"enabled\": true\n",
    "}\n",
    "\n",
    "some drills:\n",
    "\n",
    "# avg population by subregion \n",
    "select subregion, avg(population) as avg_pop, count(*) as county_count \n",
    "    from mongo.demo.europe\n",
    "    group by subregion \n",
    "\n",
    "# russian timeszones\n",
    "select name, population, flatten(timezones) from mongo.demo.europe where name = 'Russia'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d630647e-7a21-42f5-b04c-8fab775e9feb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49fbf4ca-a054-4061-81a4-e9ebaea24b66",
   "metadata": {},
   "source": [
    "## MongoDb In Spark\n",
    "\n",
    "- MongoDb has first-class support for Spark\n",
    "- When using filters with DataFrames API, the underlying Mongo Connector code constructs an aggregation pipeline to filter the data in MongoDB before sending it to Spark.\n",
    "- This ensures only the data needed is retrieved from MongoDb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bb192be-6ad3-490b-8fe3-121d1a150a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data, Surrogate key ID\n",
    "s = spark.read.option(\"multiline\",\"true\").json(\"file:///home/jovyan/datasets/json-samples/stocks.json\")\n",
    "s.write.format(\"mongo\") \\\n",
    "    .mode(\"overwrite\").option(\"database\",\"fdoc\")\\\n",
    "    .option(\"collection\",\"stocks1\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6871d04-3094-4687-9bf4-c092859719b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write data, assign an existing column as the \"_id\" before write.\n",
    "s.withColumn(\"_id\",s.symbol).write.format(\"mongo\")\\\n",
    "    .mode(\"overwrite\").option(\"database\",\"fdoc\").option(\"collection\",\"stocks2\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95048c4c-9ecd-41a9-b8ef-63460605874f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+------+\n",
      "|                 _id|  price|symbol|\n",
      "+--------------------+-------+------+\n",
      "|{6760dea42bd97450...| 126.82|  AAPL|\n",
      "|{6760dea42bd97450...|3098.12|  AMZN|\n",
      "|{6760dea42bd97450...| 251.11|    FB|\n",
      "|{6760dea42bd97450...|1725.05|  GOOG|\n",
      "|{6760dea42bd97450...| 128.39|   IBM|\n",
      "|{6760dea42bd97450...| 212.55|  MSFT|\n",
      "|{6760dea42bd97450...|   78.0|   NET|\n",
      "|{6760dea42bd97450...|  497.0|  NFLX|\n",
      "|{6760dea42bd97450...|  823.8|  TSLA|\n",
      "|{6760dea42bd97450...|  45.11|  TWTR|\n",
      "+--------------------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s2 = spark.read.format(\"mongo\").option(\"database\",\"fdoc\").option(\"collection\",\"stocks1\").load()\n",
    "s2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ba0d4-ade7-416c-87f9-6e17d1965e68",
   "metadata": {},
   "source": [
    "## Understanding how the Mongo Spark Connector Builds the aggregation pipeline\n",
    "\n",
    "In this example we demonstrate how the MongoDb connect passes most of the DataFrame tranformation logic directly to MongoDb thereby reducing the amount of computational effort expected of the Spark cluster.\n",
    "\n",
    "- `localq` processes all the transformations on spark. This consumes more memory and CPU on the spark cluster\n",
    "- `mongoq` Applies a PushedFilters and ReadSchema to MongoDb, meaning only \"Northern Europe\" documents and only the \"alpha3Code\", \"name\",\"subregion\", \"population\", and \"borders\" columns are being sent from MongoDb to Spark. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7ae5f19-b368-42ec-b056-61d56306b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_euro = spark.read.option(\"multiline\",\"true\").json(\"file:///home/jovyan/datasets/json-samples/Europe.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "316cfa5b-4d5e-4527-9548-9ed4e823dcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_euro.write.format(\"mongo\").mode(\"overwrite\").option(\"database\",\"fdoc\").option(\"collection\",\"europe\").save()\n",
    "mongo_euro = spark.read.format(\"mongo\").option(\"database\",\"fdoc\").option(\"collection\",\"europe\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c296a915-996e-4092-bbef-14ab4de1d096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+---------------+----------+----------------+\n",
      "|alpha3Code|               name|      subregion|population|borderAlpha3Code|\n",
      "+----------+-------------------+---------------+----------+----------------+\n",
      "|       DNK|            Denmark|Northern Europe|   5678348|             DEU|\n",
      "|       EST|            Estonia|Northern Europe|   1313271|             LVA|\n",
      "|       EST|            Estonia|Northern Europe|   1313271|             RUS|\n",
      "|       FIN|            Finland|Northern Europe|   5485215|             NOR|\n",
      "|       FIN|            Finland|Northern Europe|   5485215|             SWE|\n",
      "|       FIN|            Finland|Northern Europe|   5485215|             RUS|\n",
      "|       IRL|Republic of Ireland|Northern Europe|   6378000|             GBR|\n",
      "+----------+-------------------+---------------+----------+----------------+\n",
      "only showing top 7 rows\n",
      "\n",
      "+----------+-------------------+---------------+----------+----------------+\n",
      "|alpha3Code|               name|      subregion|population|borderAlpha3Code|\n",
      "+----------+-------------------+---------------+----------+----------------+\n",
      "|       DNK|            Denmark|Northern Europe|   5678348|             DEU|\n",
      "|       EST|            Estonia|Northern Europe|   1313271|             LVA|\n",
      "|       EST|            Estonia|Northern Europe|   1313271|             RUS|\n",
      "|       FIN|            Finland|Northern Europe|   5485215|             NOR|\n",
      "|       FIN|            Finland|Northern Europe|   5485215|             SWE|\n",
      "|       FIN|            Finland|Northern Europe|   5485215|             RUS|\n",
      "|       IRL|Republic of Ireland|Northern Europe|   6378000|             GBR|\n",
      "+----------+-------------------+---------------+----------+----------------+\n",
      "only showing top 7 rows\n",
      "\n",
      "plan for local file\n",
      "== Physical Plan ==\n",
      "*(1) Project [alpha3Code#633, name#644, subregion#650, population#647L, borderAlpha3Code#835]\n",
      "+- *(1) Generate explode(borders#636), [alpha3Code#633, name#644, population#647L, subregion#650], false, [borderAlpha3Code#835]\n",
      "   +- *(1) Filter (((isnotnull(subregion#650) AND (subregion#650 = Northern Europe)) AND (size(borders#636, true) > 0)) AND isnotnull(borders#636))\n",
      "      +- FileScan json [alpha3Code#633,borders#636,name#644,population#647L,subregion#650] Batched: false, DataFilters: [isnotnull(subregion#650), (subregion#650 = Northern Europe), (size(borders#636, true) > 0), isno..., Format: JSON, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/datasets/json-samples/Europe.json], PartitionFilters: [], PushedFilters: [IsNotNull(subregion), EqualTo(subregion,Northern Europe), IsNotNull(borders)], ReadSchema: struct<alpha3Code:string,borders:array<string>,name:string,population:bigint,subregion:string>\n",
      "\n",
      "\n",
      "plan for MongoDb\n",
      "== Physical Plan ==\n",
      "*(1) Project [alpha3Code#790, name#801, subregion#807, population#804L, borderAlpha3Code#843]\n",
      "+- *(1) Generate explode(borders#793), [alpha3Code#790, name#801, population#804L, subregion#807], false, [borderAlpha3Code#843]\n",
      "   +- *(1) Filter ((((size(borders#793, true) > 0) AND isnotnull(subregion#807)) AND (subregion#807 = Northern Europe)) AND isnotnull(borders#793))\n",
      "      +- *(1) Scan MongoRelation(MongoRDD[89] at RDD at MongoRDD.scala:51,Some(StructType(StructField(_id,StructType(StructField(oid,StringType,true)),true),StructField(alpha2Code,StringType,true),StructField(alpha3Code,StringType,true),StructField(altSpellings,ArrayType(StringType,true),true),StructField(area,DoubleType,true),StructField(borders,ArrayType(StringType,true),true),StructField(callingCodes,ArrayType(StringType,true),true),StructField(capital,StringType,true),StructField(currencies,ArrayType(StringType,true),true),StructField(demonym,StringType,true),StructField(gini,DoubleType,true),StructField(languages,ArrayType(StringType,true),true),StructField(latlng,ArrayType(DoubleType,true),true),StructField(name,StringType,true),StructField(nativeName,StringType,true),StructField(numericCode,StringType,true),StructField(population,LongType,true),StructField(region,StringType,true),StructField(relevance,StringType,true),StructField(subregion,StringType,true),StructField(timezones,ArrayType(StringType,true),true),StructField(topLevelDomain,ArrayType(StringType,true),true),StructField(translations,StructType(StructField(de,StringType,true),StructField(es,StringType,true),StructField(fr,StringType,true),StructField(it,StringType,true),StructField(ja,StringType,true)),true)))) [alpha3Code#790,borders#793,name#801,population#804L,subregion#807] PushedFilters: [IsNotNull(subregion), EqualTo(subregion,Northern Europe), IsNotNull(borders)], ReadSchema: struct<alpha3Code:string,borders:array<string>,name:string,population:bigint,subregion:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import * \n",
    "#local_euro.printSchema()\n",
    "\n",
    "# Heres a DataFrame transformation. This could be in SQL too.\n",
    "localq = local_euro.select(\"alpha3Code\", \"name\",\"subregion\", \"population\", explode(col(\"borders\")).alias(\"borderAlpha3Code\")).filter(\"subregion = 'Northern Europe'\")\n",
    "mongoq = mongo_euro.select(\"alpha3Code\", \"name\",\"subregion\", \"population\", explode(col(\"borders\")).alias(\"borderAlpha3Code\")).filter(\"subregion = 'Northern Europe'\")\n",
    "\n",
    "localq.show(7)\n",
    "mongoq.show(7)\n",
    "\n",
    "print(\"plan for local file\")\n",
    "localq.explain()\n",
    "\n",
    "print(\"plan for MongoDb\")\n",
    "mongoq.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3778c96c-771f-4918-80d8-7d8f85637423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- alpha3Code: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- subregion: string (nullable = true)\n",
      " |-- population: long (nullable = true)\n",
      " |-- borderAlpha3Code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mongoq.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c419991e-f726-4983-9106-4cb0321c3315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_id: struct<oid:string>, alpha2Code: string, alpha3Code: string, altSpellings: array<string>, area: double, borders: array<string>, callingCodes: array<string>, capital: string, currencies: array<string>, demonym: string, gini: double, languages: array<string>, latlng: array<double>, name: string, nativeName: string, numericCode: string, population: bigint, region: string, relevance: string, subregion: string, timezones: array<string>, topLevelDomain: array<string>, translations: struct<de:string,es:string,fr:string,it:string,ja:string>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mongo_euro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b17c0d0e-3995-436d-aa86-dd6bd4f67f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL ? No problem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31beeb75-aa60-4e48-b719-51d25bb7cf8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         |     euro|       true|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mongo_euro.createOrReplaceTempView(\"euro\")\n",
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44599e16-6565-4249-b410-401b3e53e9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+---------+\n",
      "|                name|         capital|      col|\n",
      "+--------------------+----------------+---------+\n",
      "|       Åland Islands|       Mariehamn|UTC+02:00|\n",
      "|             Albania|          Tirana|UTC+01:00|\n",
      "|             Andorra|Andorra la Vella|UTC+01:00|\n",
      "|             Austria|          Vienna|UTC+01:00|\n",
      "|             Belarus|           Minsk|UTC+03:00|\n",
      "|             Belgium|        Brussels|UTC+01:00|\n",
      "|Bosnia and Herzeg...|        Sarajevo|UTC+01:00|\n",
      "|            Bulgaria|           Sofia|UTC+02:00|\n",
      "|             Croatia|          Zagreb|UTC+01:00|\n",
      "|              Cyprus|         Nicosia|UTC+02:00|\n",
      "|      Czech Republic|          Prague|UTC+01:00|\n",
      "|             Denmark|      Copenhagen|UTC-04:00|\n",
      "|             Denmark|      Copenhagen|UTC-03:00|\n",
      "|             Denmark|      Copenhagen|UTC-01:00|\n",
      "|             Denmark|      Copenhagen|      UTC|\n",
      "|             Denmark|      Copenhagen|UTC+01:00|\n",
      "|             Estonia|         Tallinn|UTC+02:00|\n",
      "|       Faroe Islands|        Tórshavn|UTC+00:00|\n",
      "|             Finland|        Helsinki|UTC+02:00|\n",
      "|              France|           Paris|UTC-10:00|\n",
      "+--------------------+----------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select name, capital, explode(timezones)\n",
    "    from euro\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a448d07-dca6-47ef-81f7-735a85a64eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
