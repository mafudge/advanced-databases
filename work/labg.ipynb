{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbffc557-d9d4-4461-8785-eb022657a0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "com.datastax.spark#spark-cassandra-connector-assembly_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a1d3e988-d467-4738-9fe1-77689f85d7db;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-assembly_2.12;3.1.0 in central\n",
      "downloading https://repo1.maven.org/maven2/com/datastax/spark/spark-cassandra-connector-assembly_2.12/3.1.0/spark-cassandra-connector-assembly_2.12-3.1.0.jar ...\n",
      "\t[SUCCESSFUL ] com.datastax.spark#spark-cassandra-connector-assembly_2.12;3.1.0!spark-cassandra-connector-assembly_2.12.jar (1959ms)\n",
      ":: resolution report :: resolve 782ms :: artifacts dl 1962ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.spark#spark-cassandra-connector-assembly_2.12;3.1.0 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   1   |   1   |   1   |   0   ||   1   |   1   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a1d3e988-d467-4738-9fe1-77689f85d7db\n",
      "\tconfs: [default]\n",
      "\t1 artifacts copied, 0 already retrieved (14544kB/44ms)\n",
      "23/03/22 17:04:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "# CASSANDRA CONFIGURATION\n",
    "cassandra_host = \"cassandra\"\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName('jupyter-pyspark') \\\n",
    "      .config(\"spark.cassandra.connection.host\", cassandra_host) \\\n",
    "      .config(\"spark.jars.packages\",\"com.datastax.spark:spark-cassandra-connector-assembly_2.12:3.1.0\")\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc65441e-fd9e-4157-9bb5-52f34c12b6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- 2020census: long (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- dew_point: double (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- moon_phase: double (nullable = true)\n",
      " |-- pct_clouds: long (nullable = true)\n",
      " |-- pct_humidity: long (nullable = true)\n",
      " |-- pressure: long (nullable = true)\n",
      " |-- rainfall: double (nullable = true)\n",
      " |-- snowfall: double (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- temperature.day: double (nullable = true)\n",
      " |-- temperature.eve: double (nullable = true)\n",
      " |-- temperature.max: double (nullable = true)\n",
      " |-- temperature.min: double (nullable = true)\n",
      " |-- temperature.morn: double (nullable = true)\n",
      " |-- temperature.night: double (nullable = true)\n",
      " |-- timezone: string (nullable = true)\n",
      " |-- uv_index: double (nullable = true)\n",
      " |-- wind.direction_deg: long (nullable = true)\n",
      " |-- wind.gust: double (nullable = true)\n",
      " |-- wind.speed: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "weather = spark.read.json(\"file:///home/jovyan/datasets/weather/weather.json\")\n",
    "weather.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d0e3411-6243-4fea-81ef-ba1d296b2438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    }
   ],
   "source": [
    "print(weather.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ae7e06-3346-494d-9e9b-0816de8958c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:================================================>      (175 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(weather.select(\"date\").distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2231cba8-ccf8-4aa9-a507-e10f3a7f3ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:================================================>      (175 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(weather.select(\"city\",\"state\").distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b930fb0-7379-42e6-b6ec-145fce72511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:==================================================>   (186 + 1) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(weather.select(\"date\",\"city\",\"state\").distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "857e5226-d471-4fc7-b2ff-4f94b96184b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         description|\n",
      "+--------------------+\n",
      "|          few clouds|\n",
      "|          light rain|\n",
      "|       broken clouds|\n",
      "|           clear sky|\n",
      "|     overcast clouds|\n",
      "|          light snow|\n",
      "|    scattered clouds|\n",
      "|heavy intensity rain|\n",
      "|       moderate rain|\n",
      "|       rain and snow|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.select(\"description\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d025e-2433-4810-9ea3-1703a4f9afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Profiling. Understanding your data set.\n",
    "# - what is the nat / business key? date, city,state\n",
    "# - what does \"one row mean? Weather report for {city}, {state} on that {date}\n",
    "# - for each column / attribute what are the data deps?\n",
    "\n",
    "# CASSANDRA\n",
    "# - Part Key: State, City Clus: Date\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f67b5d-0048-4908-a430-865d168fd999",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q cassandra-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3d798f3-5cfa-4198-9480-260e8d687512",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "create table if not exists glab.weather (\n",
    "  census2020 int,\n",
    "  city text,\n",
    "  condition text,\n",
    "  weatherdate date,\n",
    "  description text,\n",
    "  dew_point decimal,\n",
    "  latitude decimal,\n",
    "  longitude decimal, \n",
    "  moon_phase decimal,\n",
    "  pct_clouds int, \n",
    "  pct_humidity int, \n",
    "  pressure int, \n",
    "  rainfall decimal, \n",
    "  snowfall decimal, \n",
    "  state text,\n",
    "  temperature_day decimal,\n",
    "  temperature_eve decimal,\n",
    "  temperature_max decimal,\n",
    "  temperature_min decimal,\n",
    "  temperature_morn decimal,\n",
    "  temperature_night decimal,\n",
    "  timezone text,\n",
    "  uv_index decimal,\n",
    "  wind_direction_deg int,\n",
    "  wind_gust decimal,\n",
    "  wind_speed decimal,\n",
    "primary key ( (state,city),weatherdate )\n",
    ");\n",
    "'''\n",
    "from cassandra.cluster import Cluster\n",
    "with Cluster([cassandra_host]) as cluster:\n",
    "    session = cluster.connect()\n",
    "    session.execute(sql)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85887af5-0db4-4dc6-a73f-eef3c019f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = '''\n",
    "create table if not exists glab.weather_by_date (\n",
    "  census2020 int,\n",
    "  city text,\n",
    "  condition text,\n",
    "  weatherdate date,\n",
    "  description text,\n",
    "  dew_point decimal,\n",
    "  latitude decimal,\n",
    "  longitude decimal, \n",
    "  moon_phase decimal,\n",
    "  pct_clouds int, \n",
    "  pct_humidity int, \n",
    "  pressure int, \n",
    "  rainfall decimal, \n",
    "  snowfall decimal, \n",
    "  state text,\n",
    "  temperature_day decimal,\n",
    "  temperature_eve decimal,\n",
    "  temperature_max decimal,\n",
    "  temperature_min decimal,\n",
    "  temperature_morn decimal,\n",
    "  temperature_night decimal,\n",
    "  timezone text,\n",
    "  uv_index decimal,\n",
    "  wind_direction_deg int,\n",
    "  wind_gust decimal,\n",
    "  wind_speed decimal,\n",
    "primary key ( weatherdate,state,city )\n",
    ");\n",
    "'''\n",
    "from cassandra.cluster import Cluster\n",
    "with Cluster([cassandra_host]) as cluster:\n",
    "    session = cluster.connect()\n",
    "    session.execute(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8702c979-c4ff-428e-86ac-fc48f414b781",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = weather.toDF(\"census2020\",\"city\",\"condition\",\"weatherdate\",\"description\",\"dew_point\",\n",
    "                 \"latitude\",\"longitude\",\"moon_phase\",\"pct_clouds\",\"pct_humidity\",\"pressure\",\n",
    "                 \"rainfall\",\"snowfall\",\"state\",\"temperature_day\",\"temperature_eve\",\"temperature_max\",\n",
    "                 \"temperature_min\",\"temperature_morn\",\"temperature_night\",\"timezone\",\"uv_index\",\n",
    "                 \"wind_direction_deg\",\"wind_gust\",\"wind_speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "958a7a5b-4824-4184-81c5-2fe8d845b9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "w.write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "  .mode(\"Append\")\\\n",
    "  .options(table=\"weather_by_date\", keyspace = \"glab\")\\\n",
    "  .option(\"table\", \"weather_by_date\")\\\n",
    "  .option(\"keyspace\",\"glab\")\\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f304f111-1cbe-4bdb-8e1b-aaf74583db49",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "  .mode(\"Append\")\\\n",
    "  .option(\"table\", \"weather\")\\\n",
    "  .option(\"keyspace\",\"glab\")\\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c993bfd-7f62-4062-acea-4c593cd3781c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "  .option(\"table\", \"weather_by_date\")\\\n",
    "  .option(\"keyspace\",\"glab\")\\\n",
    "  .load()\n",
    "w2.createOrReplaceTempView(\"daily_city_weather_by_date\")\n",
    "w2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87836f54-db92-4eee-9907-03bc2169bc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2 = spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "  .option(\"table\", \"weather\")\\\n",
    "  .option(\"keyspace\",\"glab\")\\\n",
    "  .load()\n",
    "w2.createOrReplaceTempView(\"daily_city_weather\")\n",
    "w2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc57e430-3a05-4b7f-bbc1-4059fb25cdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [city#671, state#670, weatherdate#672, condition#674, description#675, temperature_day#685]\n",
      "+- BatchScan[state#670, city#671, weatherdate#672, condition#674, description#675, temperature_day#685] Cassandra Scan: glab.weather\n",
      " - Cassandra Filters: [[\"state\" = ?, New York],[\"city\" = ?, Syracuse]]\n",
      " - Requested Columns: [state,city,weatherdate,condition,description,temperature_day]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select city,state,weatherdate,condition,description,temperature_day \n",
    "    from daily_city_weather \n",
    "    where city='Syracuse' and state='New York';\n",
    "'''\n",
    "spark.sql(query).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19375aa4-5e9a-4c11-a90e-3597d3cf3553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|moon_phase|\n",
      "+----------+\n",
      "|      0.66|\n",
      "|      0.54|\n",
      "|       0.6|\n",
      "|      0.63|\n",
      "|      0.68|\n",
      "|      0.57|\n",
      "|       0.5|\n",
      "|      0.62|\n",
      "|      0.56|\n",
      "|      0.65|\n",
      "|      0.47|\n",
      "|      0.53|\n",
      "|      0.59|\n",
      "|      0.69|\n",
      "|      0.48|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w.select(\"moon_phase\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c5eb75b-e1d4-46e2-9834-3e080dff0975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [city#766, state#765, weatherdate#767, condition#769, description#770, temperature_day#780]\n",
      "+- *(1) Filter (moon_phase#774 = 0.500000000000000000)\n",
      "   +- BatchScan[state#765, city#766, weatherdate#767, condition#769, description#770, moon_phase#774, temperature_day#780] Cassandra Scan: glab.weather\n",
      " - Cassandra Filters: []\n",
      " - Requested Columns: [state,city,weatherdate,condition,description,moon_phase,temperature_day]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select city,state,weatherdate,condition,description,temperature_day \n",
    "    from daily_city_weather \n",
    "    where moon_phase=0.5;\n",
    "'''\n",
    "spark.sql(query).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d17d6d9f-cfbe-4259-b26e-983de87c9bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [city#766, state#765, weatherdate#767, condition#769, description#770, temperature_day#780]\n",
      "+- BatchScan[state#765, city#766, weatherdate#767, condition#769, description#770, temperature_day#780] Cassandra Scan: glab.weather\n",
      " - Cassandra Filters: [[\"condition\" = ?, Rain]]\n",
      " - Requested Columns: [state,city,weatherdate,condition,description,temperature_day]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select city,state,weatherdate,condition,description,temperature_day \n",
    "    from daily_city_weather \n",
    "    where condition='Rain';\n",
    "'''\n",
    "spark.sql(query).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00b438de-cc3c-42ca-9822-6dac102ccdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+-----------+---------+-------------+--------------------+\n",
      "|          city|         state|weatherdate|condition|  description|     temperature_day|\n",
      "+--------------+--------------+-----------+---------+-------------+--------------------+\n",
      "| Moreno Valley|    California| 2021-10-23|     Rain|   light rain|61.93000000000000...|\n",
      "|        Dallas|         Texas| 2021-10-26|     Rain|moderate rain|72.57000000000000...|\n",
      "|   Baton Rouge|     Louisiana| 2021-10-26|     Rain|   light rain|82.87000000000000...|\n",
      "|Virginia Beach|      Virginia| 2021-10-26|     Rain|   light rain|61.45000000000000...|\n",
      "|       Hayward|    California| 2021-10-21|     Rain|moderate rain|67.78000000000000...|\n",
      "|Pembroke Pines|       Florida| 2021-10-26|     Rain|   light rain|83.70000000000000...|\n",
      "|    Pittsburgh|  Pennsylvania| 2021-10-22|     Rain|   light rain|53.62000000000000...|\n",
      "|    Cincinnati|          Ohio| 2021-10-26|     Rain|   light rain|82.08000000000000...|\n",
      "|        Mobile|       Alabama| 2021-10-20|     Rain|   light rain|75.92000000000000...|\n",
      "|     Rochester|      New York| 2021-10-25|     Rain|moderate rain|43.88000000000000...|\n",
      "|     Elk Grove|    California| 2021-10-21|     Rain|moderate rain|66.33000000000000...|\n",
      "|      Syracuse|      New York| 2021-10-21|     Rain|moderate rain|63.57000000000000...|\n",
      "|      Bellevue|    Washington| 2021-10-20|     Rain|moderate rain|52.52000000000000...|\n",
      "|       Raleigh|North Carolina| 2021-10-22|     Rain|   light rain|75.67000000000000...|\n",
      "|        Joliet|      Illinois| 2021-10-25|     Rain|moderate rain|72.32000000000000...|\n",
      "|Corpus Christi|         Texas| 2021-10-23|     Rain|   light rain|84.16000000000000...|\n",
      "|        Aurora|      Illinois| 2021-10-24|     Rain|   light rain|53.98000000000000...|\n",
      "| Oklahoma City|      Oklahoma| 2021-10-26|     Rain|   light rain|75.31000000000000...|\n",
      "|     Hollywood|       Florida| 2021-10-23|     Rain|   light rain|83.32000000000000...|\n",
      "|         Miami|       Florida| 2021-10-22|     Rain|   light rain|81.86000000000000...|\n",
      "+--------------+--------------+-----------+---------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select city,state,weatherdate,condition,description,temperature_day \n",
    "    from daily_city_weather \n",
    "    where condition = 'Rain'\n",
    "union \n",
    "select city,state,weatherdate,condition,description,temperature_day \n",
    "    from daily_city_weather \n",
    "    where condition = 'Cloudy';\n",
    "'''\n",
    "spark.sql(query).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1002a741-08d7-4b5f-92d1-31a6a6bf5e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"condition\":\"Clear\"}',\n",
       " '{\"condition\":\"Clouds\"}',\n",
       " '{\"condition\":\"Rain\"}',\n",
       " '{\"condition\":\"Snow\"}']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.select(\"condition\").distinct().toJSON().collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dcee6442-83f0-44d8-8ee8-a397c3e6b21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>weatherdate</th>\n",
       "      <th>condition</th>\n",
       "      <th>description</th>\n",
       "      <th>temperature_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mobile</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>Rain</td>\n",
       "      <td>light rain</td>\n",
       "      <td>82.710000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Montgomery</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>Rain</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>78.240000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Little Rock</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>Rain</td>\n",
       "      <td>light rain</td>\n",
       "      <td>68.810000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bakersfield</td>\n",
       "      <td>California</td>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>Rain</td>\n",
       "      <td>light rain</td>\n",
       "      <td>73.690000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elk Grove</td>\n",
       "      <td>California</td>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>Rain</td>\n",
       "      <td>heavy intensity rain</td>\n",
       "      <td>57.880000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Bellevue</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>Rain</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>55.630000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>Rain</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>55.000000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Spokane</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>Rain</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>51.370000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Tacoma</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>Rain</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>55.240000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>Rain</td>\n",
       "      <td>moderate rain</td>\n",
       "      <td>52.830000000000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city       state weatherdate condition           description  \\\n",
       "0        Mobile     Alabama  2021-10-22      Rain            light rain   \n",
       "1    Montgomery     Alabama  2021-10-22      Rain         moderate rain   \n",
       "2   Little Rock    Arkansas  2021-10-22      Rain            light rain   \n",
       "3   Bakersfield  California  2021-10-22      Rain            light rain   \n",
       "4     Elk Grove  California  2021-10-22      Rain  heavy intensity rain   \n",
       "..          ...         ...         ...       ...                   ...   \n",
       "75     Bellevue  Washington  2021-10-22      Rain         moderate rain   \n",
       "76      Seattle  Washington  2021-10-22      Rain         moderate rain   \n",
       "77      Spokane  Washington  2021-10-22      Rain         moderate rain   \n",
       "78       Tacoma  Washington  2021-10-22      Rain         moderate rain   \n",
       "79    Vancouver  Washington  2021-10-22      Rain         moderate rain   \n",
       "\n",
       "          temperature_day  \n",
       "0   82.710000000000000000  \n",
       "1   78.240000000000000000  \n",
       "2   68.810000000000000000  \n",
       "3   73.690000000000000000  \n",
       "4   57.880000000000000000  \n",
       "..                    ...  \n",
       "75  55.630000000000000000  \n",
       "76  55.000000000000000000  \n",
       "77  51.370000000000000000  \n",
       "78  55.240000000000000000  \n",
       "79  52.830000000000000000  \n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "select city,state,weatherdate,condition,description,temperature_day \n",
    "    from daily_city_weather \n",
    "    where condition='Rain' and weatherdate='2021-10-22'\n",
    "'''\n",
    "spark.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "082e7eda-397c-4f52-9ae4-01c0d65d9b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [city#363, state#362, weatherdate#364, condition#366, description#367, temperature_day#377]\n",
      "+- BatchScan[state#362, city#363, weatherdate#364, condition#366, description#367, temperature_day#377] Cassandra Scan: glab.weather\n",
      " - Cassandra Filters: [[\"weatherdate\" = ?, 2021-10-22],[\"condition\" = ?, Rain]]\n",
      " - Requested Columns: [state,city,weatherdate,condition,description,temperature_day]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select city,state,weatherdate,condition,description,temperature_day \n",
    "    from daily_city_weather \n",
    "    where condition='Rain' and weatherdate='2021-10-22'\n",
    "'''\n",
    "spark.sql(query).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a812d812-242d-4325-a81c-b5383bac8217",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view not found: daily_city_weather_by_date; line 3 pos 9;\n'Project ['city, 'state, 'weatherdate, 'condition, 'description, 'temperature_day]\n+- 'Filter (('condition = Rain) AND ('weatherdate = 2021-10-22))\n   +- 'UnresolvedRelation [daily_city_weather_by_date], [], false\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_65/1277696974.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwhere\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Rain'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mweatherdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2021-10-22'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m '''\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \"\"\"\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtableName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table or view not found: daily_city_weather_by_date; line 3 pos 9;\n'Project ['city, 'state, 'weatherdate, 'condition, 'description, 'temperature_day]\n+- 'Filter (('condition = Rain) AND ('weatherdate = 2021-10-22))\n   +- 'UnresolvedRelation [daily_city_weather_by_date], [], false\n"
     ]
    }
   ],
   "source": [
    "query = '''\n",
    "select city,state,weatherdate,condition,description,temperature_day \n",
    "    from daily_city_weather_by_date \n",
    "    where condition='Rain' and weatherdate='2021-10-22'\n",
    "'''\n",
    "spark.sql(query).explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ff856a-4eef-4b2a-9b79-d2db94abdb4e",
   "metadata": {},
   "source": [
    "Create cassandra indexes:\n",
    "    \n",
    "    create index ix_condition_by_date on weather_by_date(condition);\n",
    "    create index ix_condition on weather(condition);\n",
    "    \n",
    "**IMPORTANT** Now to see the indexes in spark, we must reload the dataframes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa332d67-2a14-4400-8268-f1c4b132f28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [city#252, state#251, weatherdate#253, condition#255, description#256, temperature_day#266]\n",
      "+- BatchScan[state#251, city#252, weatherdate#253, condition#255, description#256, temperature_day#266] Cassandra Scan: glab.weather\n",
      " - Cassandra Filters: [[\"weatherdate\" = ?, 2021-10-22],[\"condition\" = ?, Rain]]\n",
      " - Requested Columns: [state,city,weatherdate,condition,description,temperature_day]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2 = spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "  .options(table=\"weather\",keyspace=\"glab\")\\\n",
    "  .load()\n",
    "\n",
    "w2.createOrReplaceTempView(\"daily_city_weather\")\n",
    "query = '''\n",
    "select city,state,weatherdate,condition,description,temperature_day \n",
    "    from daily_city_weather \n",
    "    where condition='Rain' and weatherdate='2021-10-22'\n",
    "'''\n",
    "spark.sql(query).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68d75a02-a95d-4c52-ad5b-7bdbc1ebb67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function print in module builtins:\n",
      "\n",
      "print(...)\n",
      "    print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False)\n",
      "    \n",
      "    Prints the values to a stream, or to sys.stdout by default.\n",
      "    Optional keyword arguments:\n",
      "    file:  a file-like object (stream); defaults to the current sys.stdout.\n",
      "    sep:   string inserted between values, default a space.\n",
      "    end:   string appended after the last value, default a newline.\n",
      "    flush: whether to forcibly flush the stream.\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75831e81-4a86-4938-aaac-dc531e50e98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [state#341, city#342, weatherdate#343, census2020#344, condition#345, description#346, dew_point#347, latitude#348, longitude#349, moon_phase#350, pct_clouds#351, pct_humidity#352, pressure#353, rainfall#354, snowfall#355, temperature_day#356, temperature_eve#357, temperature_max#358, temperature_min#359, temperature_morn#360, temperature_night#361, timezone#362, uv_index#363, wind_direction_deg#364, ... 2 more fields]\n",
      "+- BatchScan[state#341, city#342, weatherdate#343, census2020#344, condition#345, description#346, dew_point#347, latitude#348, longitude#349, moon_phase#350, pct_clouds#351, pct_humidity#352, pressure#353, rainfall#354, snowfall#355, temperature_day#356, temperature_eve#357, temperature_max#358, temperature_min#359, temperature_morn#360, temperature_night#361, timezone#362, uv_index#363, wind_direction_deg#364, ... 2 more fields] Cassandra Scan: glab.weather\n",
      " - Cassandra Filters: [[\"weatherdate\" = ?, 2021-10-22],[\"condition\" = ?, Rain]]\n",
      " - Requested Columns: [state,city,weatherdate,census2020,condition,description,dew_point,latitude,longitude,moon_phase,pct_clouds,pct_humidity,pressure,rainfall,snowfall,temperature_day,temperature_eve,temperature_max,temperature_min,temperature_morn,temperature_night,timezone,uv_index,wind_direction_deg,wind_gust,wind_speed]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2 = spark.read.format(\"org.apache.spark.sql.cassandra\")\\\n",
    "  .option(\"table\", \"weather\")\\\n",
    "  .option(\"keyspace\",\"glab\")\\\n",
    "  .load()\n",
    "w2.where(\"weatherdate='2021-10-22' and condition='Rain'\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c37dfc-5044-4099-9c6f-261ae992f23c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
